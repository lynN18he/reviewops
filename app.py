"""
ReviewOps - ç”¨æˆ·åé¦ˆå†³ç­–ä¸­å°
ä¸€ä¸ªå¸®åŠ©äº§å“ç»ç†åˆ†æç”¨æˆ·åé¦ˆçš„ Bç«¯ SaaS åŸå‹
"""

import streamlit as st
import pandas as pd
import time
from collections import Counter
import re
import plotly.express as px
import plotly.graph_objects as go
import os
import json
from enum import Enum
from typing import Optional
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# RAG ç›¸å…³å¯¼å…¥
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.chat_models import ChatTongyi
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate

# Pydantic æ¨¡å‹ï¼ˆå¦‚æœæœªå®‰è£…ï¼Œä½¿ç”¨åŸºç¡€å­—å…¸ï¼‰
try:
    from pydantic import BaseModel, ConfigDict
    PYDANTIC_AVAILABLE = True
except ImportError:
    PYDANTIC_AVAILABLE = False
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„ BaseModel æ›¿ä»£
    class BaseModel:
        pass
    ConfigDict = None

# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="ReviewOps Â· ç”¨æˆ·åé¦ˆå†³ç­–ä¸­å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== è‡ªå®šä¹‰æ ·å¼ ====================
st.markdown("""
<style>
    /* ä¸»é¢˜è‰²å½©ç³»ç»Ÿ */
    :root {
        --primary: #6366f1;
        --secondary: #8b5cf6;
        --accent: #06b6d4;
        --success: #10b981;
        --warning: #f59e0b;
        --danger: #ef4444;
    }
    
    /* æŒ‡æ ‡å¡ç‰‡æ ·å¼ */
    [data-testid="stMetric"] {
        background: linear-gradient(135deg, #1e1b4b 0%, #312e81 100%);
        padding: 1.2rem;
        border-radius: 12px;
        border: 1px solid rgba(99, 102, 241, 0.3);
        box-shadow: 0 4px 20px rgba(99, 102, 241, 0.15);
    }
    
    [data-testid="stMetric"] label {
        color: #a5b4fc !important;
        font-weight: 500;
    }
    
    [data-testid="stMetric"] [data-testid="stMetricValue"] {
        color: #e0e7ff !important;
        font-weight: 700;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ - ä¼˜åŒ–é¢œè‰²ä½¿å…¶æ›´æ˜æ˜¾å’Œç”¨æˆ·å‹å¥½ */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1e293b 0%, #334155 100%) !important;
        border-right: 2px solid rgba(99, 102, 241, 0.3);
    }
    
    [data-testid="stSidebar"] .stMarkdown h1,
    [data-testid="stSidebar"] .stMarkdown h2,
    [data-testid="stSidebar"] .stMarkdown h3 {
        color: #e0e7ff !important;
        font-weight: 600;
    }
    
    [data-testid="stSidebar"] .stMarkdown p,
    [data-testid="stSidebar"] .stMarkdown {
        color: #cbd5e1 !important;
    }
    
    [data-testid="stSidebar"] .stInfo {
        background-color: rgba(99, 102, 241, 0.15) !important;
        border-left: 3px solid #6366f1 !important;
        color: #e0e7ff !important;
    }
    
    [data-testid="stSidebar"] .stSuccess {
        background-color: rgba(16, 185, 129, 0.15) !important;
        border-left: 3px solid #10b981 !important;
        color: #d1fae5 !important;
    }
    
    [data-testid="stSidebar"] .stWarning {
        background-color: rgba(245, 158, 11, 0.15) !important;
        border-left: 3px solid #f59e0b !important;
        color: #fef3c7 !important;
    }
    
    [data-testid="stSidebar"] .stCaption {
        color: #94a3b8 !important;
    }
    
    [data-testid="stSidebar"] .stDivider {
        border-color: rgba(99, 102, 241, 0.2) !important;
    }
    
    [data-testid="stSidebar"] input[type="text"],
    [data-testid="stSidebar"] input[type="password"] {
        background-color: rgba(30, 41, 59, 0.5) !important;
        border: 1px solid rgba(99, 102, 241, 0.3) !important;
        color: #e0e7ff !important;
    }
    
    [data-testid="stSidebar"] input[type="text"]:focus,
    [data-testid="stSidebar"] input[type="password"]:focus {
        border-color: #6366f1 !important;
        box-shadow: 0 0 0 2px rgba(99, 102, 241, 0.2) !important;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
        color: white;
        border: none;
        padding: 0.75rem 2rem;
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(99, 102, 241, 0.4);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 25px rgba(99, 102, 241, 0.5);
    }
    
    /* è¡¨æ ¼æ ·å¼ */
    .stDataFrame {
        border-radius: 12px;
        overflow: hidden;
    }
    
    /* Expander æ ·å¼ */
    .streamlit-expanderHeader {
        background: rgba(99, 102, 241, 0.1);
        border-radius: 8px;
    }
    
    /* ä¸»æ ‡é¢˜ */
    .main-title {
        background: linear-gradient(90deg, #6366f1, #8b5cf6, #06b6d4);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 2.5rem;
        font-weight: 800;
        margin-bottom: 0;
    }
    
    /* ä¿¡æ¯å¡ç‰‡ */
    .info-card {
        background: linear-gradient(135deg, #1e1b4b 0%, #312e81 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid rgba(99, 102, 241, 0.3);
        margin: 1rem 0;
    }
    
    /* è¡ŒåŠ¨é¡¹å¡ç‰‡å®¹å™¨ */
    .action-card {
        background: #ffffff;
        border-radius: 12px;
        padding: 1.25rem 1.5rem;
        margin-bottom: 1rem;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        border: 1px solid #e5e7eb;
        transition: all 0.2s ease;
    }
    
    .action-card:hover {
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.12);
        transform: translateY(-2px);
    }
    
    /* é«˜ä¼˜å…ˆçº§ */
    .action-card.high-priority {
        border-left: 4px solid #ef4444;
    }
    
    /* ä¸­ä¼˜å…ˆçº§ */
    .action-card.medium-priority {
        border-left: 4px solid #f59e0b;
    }
    
    /* å¸¸è§„ä¼˜å…ˆçº§ */
    .action-card.low-priority {
        border-left: 4px solid #10b981;
    }
    
    /* ä¼˜å…ˆçº§æ ‡ç­¾ */
    .priority-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-right: 0.5rem;
    }
    
    .priority-badge.high {
        background: #fef2f2;
        color: #dc2626;
    }
    
    .priority-badge.medium {
        background: #fffbeb;
        color: #d97706;
    }
    
    .priority-badge.low {
        background: #ecfdf5;
        color: #059669;
    }
    
    /* è¡ŒåŠ¨æ ‡é¢˜ */
    .action-title {
        font-size: 1.1rem;
        font-weight: 600;
        color: #1f2937;
        margin: 0.5rem 0;
    }
    
    /* è¡ŒåŠ¨è¯¦æƒ… */
    .action-detail {
        color: #4b5563;
        font-size: 0.95rem;
        line-height: 1.6;
        margin: 0.75rem 0;
    }
    
    /* å…ƒä¿¡æ¯ */
    .action-meta {
        display: flex;
        gap: 1.5rem;
        margin-top: 1rem;
        padding-top: 0.75rem;
        border-top: 1px solid #f3f4f6;
    }
    
    .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
        color: #6b7280;
        font-size: 0.85rem;
    }
    
    .meta-item strong {
        color: #374151;
    }
    
    /* åˆ†å‰²çº¿ */
    hr {
        border: none;
        height: 1px;
        background: linear-gradient(90deg, transparent, rgba(99, 102, 241, 0.5), transparent);
        margin: 2rem 0;
    }
    
    /* Toast é€šçŸ¥ä½ç½®è°ƒæ•´ - è®©å¼¹æ¡†æ›´é è¿‘æŒ‰é’® */
    [data-testid="stToast"] {
        position: fixed !important;
        top: 20px !important;
        right: 20px !important;
        z-index: 999999 !important;
        min-width: 300px !important;
        max-width: 400px !important;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3) !important;
        border-radius: 12px !important;
        animation: slideInRight 0.3s ease-out !important;
    }
    
    @keyframes slideInRight {
        from {
            transform: translateX(100%);
            opacity: 0;
        }
        to {
            transform: translateX(0);
            opacity: 1;
        }
    }
    
    /* ç¡®ä¿ toast å†…å®¹å¯è§ */
    [data-testid="stToast"] > div {
        background: linear-gradient(135deg, #1e293b 0%, #334155 100%) !important;
        color: #e0e7ff !important;
        padding: 1rem 1.25rem !important;
        border: 1px solid rgba(99, 102, 241, 0.3) !important;
    }
    
    [data-testid="stToast"] [data-baseweb="notification"] {
        background: transparent !important;
        color: #e0e7ff !important;
    }
</style>
""", unsafe_allow_html=True)


# ==================== æ•°æ®åŠ è½½ ====================
@st.cache_data(ttl=60)  # 60ç§’ç¼“å­˜ï¼Œä¾¿äºå¼€å‘
def load_reviews():
    """åŠ è½½ç”¨æˆ·è¯„è®ºæ•°æ®"""
    df = pd.read_csv("user_reviews.csv")
    # ç¡®ä¿æœ‰ review_id åˆ—ï¼ˆå¦‚æœæ²¡æœ‰ï¼Œä½¿ç”¨ user_id æˆ–åˆ›å»ºï¼‰
    if 'review_id' not in df.columns:
        if 'user_id' in df.columns:
            df['review_id'] = df['user_id']
        else:
            df['review_id'] = range(1, len(df) + 1)
    return df


# æ¸…é™¤ç¼“å­˜ä»¥ä¾¿é‡æ–°åŠ è½½æ•°æ®
load_reviews.clear()

# åŠ è½½æ•°æ®
reviews_df = load_reviews()


# ==================== RAG åˆå§‹åŒ– ====================
@st.cache_resource
def init_vectorstore(api_key):
    """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
    if not api_key:
        return None
    
    try:
        embeddings = DashScopeEmbeddings(
            model="text-embedding-v3",  # ä¸ injest.py ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ v3 æ¨¡å‹ï¼ˆ1536 ç»´ï¼‰
            dashscope_api_key=api_key
        )
        
        vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=embeddings
        )
        return vectorstore
    except Exception as e:
        st.error(f"å‘é‡åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


@st.cache_resource
def init_llm(api_key):
    """åˆå§‹åŒ– LLM"""
    if not api_key:
        return None
    
    try:
        from langchain_community.chat_models import ChatTongyi
        llm = ChatTongyi(
            model="qwen-plus",
            temperature=0,
            dashscope_api_key=api_key
        )
        return llm
    except Exception as e:
        st.error(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def perform_rag_query(vectorstore, llm, question):
    """æ‰§è¡Œ RAG æŸ¥è¯¢ï¼šæ£€ç´¢ + ç”Ÿæˆ"""
    if not vectorstore or not llm:
        return None, []
    
    try:
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆä½¿ç”¨ similarity_search_with_score è·å–è·ç¦»åˆ†æ•°ï¼‰
        # ä½¿ç”¨æ›´å¤§çš„ k å€¼ï¼Œç„¶åå»é‡å’Œè¿‡æ»¤
        try:
            docs_with_scores = vectorstore.similarity_search_with_score(question, k=10)
        except:
            # å¦‚æœä¸æ”¯æŒ similarity_search_with_scoreï¼Œå›é€€åˆ°æ™®é€šæœç´¢
            docs = vectorstore.similarity_search(question, k=5)
            # ç®€å•å»é‡ï¼Œè¿”å›æ‰€æœ‰ä¸é‡å¤çš„æ–‡æ¡£
            unique_docs = []
            seen_contents = set()
            for doc in docs:
                content_fingerprint = doc.page_content[:150].strip()
                if content_fingerprint not in seen_contents:
                    seen_contents.add(content_fingerprint)
                    unique_docs.append(doc)
            docs = unique_docs  # è¿”å›æ‰€æœ‰å»é‡åçš„æ–‡æ¡£ï¼Œä¸é™åˆ¶æ•°é‡
        else:
            # 2. å»é‡ï¼šåŸºäºæ–‡æ¡£å†…å®¹çš„ç›¸ä¼¼åº¦å»é‡
            # ChromaDB è¿”å›çš„æ˜¯è·ç¦»ï¼ˆdistanceï¼‰ï¼Œè¶Šå°è¶Šç›¸ä¼¼
            # é€šå¸¸è·ç¦» < 1.5 è¡¨ç¤ºæ¯”è¾ƒç›¸å…³
            unique_docs = []
            seen_contents = set()
            max_distance = 1.5  # æœ€å¤§è·ç¦»é˜ˆå€¼ï¼ˆæ ¹æ®å®é™…è°ƒæ•´ï¼‰
            
            for doc, distance in docs_with_scores:
                # è¿‡æ»¤è·ç¦»è¿‡å¤§çš„ç»“æœï¼ˆç›¸ä¼¼åº¦å¤ªä½ï¼‰
                if distance > max_distance:
                    continue
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦é‡å¤ï¼ˆä½¿ç”¨å‰150ä¸ªå­—ç¬¦ä½œä¸ºæŒ‡çº¹ï¼Œæ›´å‡†ç¡®ï¼‰
                content_fingerprint = doc.page_content[:150].strip()
                if content_fingerprint not in seen_contents:
                    seen_contents.add(content_fingerprint)
                    unique_docs.append(doc)
                    # ä¸å†é™åˆ¶æ•°é‡ï¼Œè¿”å›æ‰€æœ‰ç›¸å…³ä¸”ä¸é‡å¤çš„æ–‡æ¡£
            
            docs = unique_docs  # è¿”å›æ‰€æœ‰ç›¸å…³ä¸”å»é‡åçš„æ–‡æ¡£
        
        # 3. æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([doc.page_content for doc in docs])
        
        # 3. æ„å»º Prompt
        system_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·åé¦ˆå’Œäº§å“è¯´æ˜ä¹¦ï¼Œè¿›è¡Œå‡†ç¡®çš„å½’å› åˆ†æã€‚

è¯·åŸºäºä»¥ä¸‹äº§å“è¯´æ˜ä¹¦å†…å®¹ï¼Œåˆ†æç”¨æˆ·åé¦ˆé—®é¢˜ï¼š
{context}

å›ç­”æ ¼å¼ï¼š
- è¯´æ˜ä¹¦å¯¹åº”å‚æ•°ï¼š[ä»äº§å“è¯´æ˜ä¹¦ä¸­æå–çš„ç›¸å…³å†…å®¹]
- AI åˆ¤å®šç»“è®ºï¼š[ä½ çš„åˆ¤æ–­ï¼Œå¦‚æœæ˜¯å·²çŸ¥å±€é™ç”¨âœ…ï¼Œå¦‚æœæ˜¯æ–°é—®é¢˜ç”¨âš ï¸ï¼Œå¦‚æœæ˜¯ç”¨æˆ·è¯¯ç”¨ç”¨â“]

å›ç­”ï¼š"""
        
        human_template = "ç”¨æˆ·åé¦ˆï¼š{question}"
        
        messages = [
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ]
        
        prompt = ChatPromptTemplate.from_messages(messages)
        
        # 4. è°ƒç”¨ LLM
        formatted_prompt = prompt.format_messages(context=context, question=question)
        response = llm.invoke(formatted_prompt)
        
        # 5. æå–å›ç­”
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
        
        return answer, docs
        
    except Exception as e:
        st.warning(f"RAG æŸ¥è¯¢å‡ºé”™: {e}")
        return None, []


# ==================== è¾…åŠ©å‡½æ•° ====================
def extract_product_name():
    """ä» PDF æ–‡ä»¶åæˆ–å‘é‡åº“ä¸­æå–äº§å“åç§°"""
    # ä» PDF æ–‡ä»¶åæå–ï¼ˆdji_spec.pdf -> DJIï¼‰
    pdf_name = "dji_spec.pdf"
    if os.path.exists(pdf_name):
        # ä»æ–‡ä»¶åæå–äº§å“å
        name = pdf_name.replace("_spec.pdf", "").replace(".pdf", "").upper()
        return name
    return "äº§å“è¯´æ˜ä¹¦"


def calculate_metrics(df):
    """è®¡ç®—å…³é”®æŒ‡æ ‡ - ç¡®ä¿æ‰€æœ‰è¯„è®ºï¼ˆåŒ…æ‹¬æ­£é¢å’Œè´Ÿé¢ï¼‰éƒ½è¢«æ­£ç¡®ç»Ÿè®¡"""
    # å¤„ç†ç©º DataFrame
    if df.empty or len(df) == 0:
        return 0, 0.0, 0.0
    
    total_reviews = len(df)
    
    # è®¡ç®—å¹³å‡è¯„åˆ†ï¼Œå¤„ç† NaN å€¼
    # é‡è¦ï¼šå¿…é¡»è®¡ç®—æ‰€æœ‰è¯„è®ºçš„å¹³å‡åˆ†ï¼ŒåŒ…æ‹¬æ­£é¢ã€è´Ÿé¢å’Œä¸­æ€§è¯„è®º
    if 'rating' not in df.columns:
        avg_rating = 0.0
    else:
        # ç¡®ä¿ rating æ˜¯æ•°å€¼ç±»å‹
        rating_series = pd.to_numeric(df['rating'], errors='coerce')
        # è¿‡æ»¤æ‰ NaN å€¼åè®¡ç®—å¹³å‡å€¼ï¼ˆåŒ…æ‹¬æ‰€æœ‰æœ‰æ•ˆè¯„åˆ†ï¼‰
        valid_ratings = rating_series.dropna()
        if len(valid_ratings) > 0:
            # è®¡ç®—æ‰€æœ‰æœ‰æ•ˆè¯„åˆ†çš„å¹³å‡å€¼ï¼ˆåŒ…æ‹¬ 1-5 æ˜Ÿçš„æ‰€æœ‰è¯„åˆ†ï¼‰
            avg_rating = float(valid_ratings.mean())
        else:
            avg_rating = 0.0
    
    # è®¡ç®—è´Ÿé¢è¯„ä»·å æ¯”ï¼Œå¤„ç†é™¤é›¶æƒ…å†µ
    # é‡è¦ï¼šè´Ÿé¢è¯„ä»·å æ¯” = è´Ÿé¢è¯„è®ºæ•° / æ€»è¯„è®ºæ•° * 100
    # æ€»è¯„è®ºæ•°åŒ…æ‹¬æ‰€æœ‰è¯„è®ºï¼ˆæ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ï¼‰
    if total_reviews == 0:
        negative_ratio = 0.0
    else:
        if 'rating' in df.columns:
            # ç¡®ä¿ rating æ˜¯æ•°å€¼ç±»å‹åå†æ¯”è¾ƒ
            rating_series = pd.to_numeric(df['rating'], errors='coerce')
            # è´Ÿé¢è¯„ä»·ï¼šrating < 3ï¼ˆ1æ˜Ÿå’Œ2æ˜Ÿï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œåªè®¡ç®—è´Ÿé¢è¯„è®ºæ•°ï¼Œåˆ†æ¯æ˜¯æ€»è¯„è®ºæ•°ï¼ˆåŒ…æ‹¬æ­£é¢è¯„è®ºï¼‰
            negative_count = len(rating_series[rating_series < 3].dropna())
        else:
            negative_count = 0
        # è´Ÿé¢å æ¯” = è´Ÿé¢è¯„è®ºæ•° / æ€»è¯„è®ºæ•° * 100
        negative_ratio = (negative_count / total_reviews) * 100
    
    return total_reviews, avg_rating, negative_ratio


def get_negative_reviews(df):
    """è·å–è´Ÿé¢è¯„ä»·"""
    return df[df['rating'] < 3]


def analyze_reviews_with_llm(reviews_df, llm):
    """
    ä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰èšç±»ï¼Œè‡ªåŠ¨å‘ç°ä¸»è¦æŠ±æ€¨ç‚¹
    
    Args:
        reviews_df: åŒ…å« review_text å’Œ user_id (æˆ– review_id) çš„ DataFrame
        llm: LangChain LLM å®ä¾‹
    
    Returns:
        list: åŒ…å« topics çš„åˆ—è¡¨ï¼Œæ¯ä¸ª topic åŒ…å« topic, review_ids, summary
    """
    if reviews_df.empty:
        return []
    
    # ç¡®ä¿æœ‰ review_id æˆ– user_id åˆ—
    if 'review_id' not in reviews_df.columns and 'user_id' in reviews_df.columns:
        reviews_df = reviews_df.copy()
        reviews_df['review_id'] = reviews_df['user_id']
    elif 'review_id' not in reviews_df.columns:
        reviews_df = reviews_df.copy()
        reviews_df['review_id'] = range(1, len(reviews_df) + 1)
    
    # æ„å»ºè¯„è®ºæ–‡æœ¬ï¼ŒåŒ…å« ID ä¿¡æ¯
    review_texts = []
    for idx, row in reviews_df.iterrows():
        review_id = row['review_id']
        review_text = row['review_text'] if 'review_text' in row else row.get('content', '')
        if review_text and not pd.isna(review_text):
            review_texts.append(f"è¯„è®ºID {review_id}: {review_text}")
    
    if not review_texts:
        return []
    
    # æ‹¼æ¥æ‰€æœ‰è¯„è®º
    all_reviews = "\n\n".join(review_texts)
    
    # æ„å»º Prompt
    prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“åé¦ˆåˆ†æå¸ˆã€‚è¯·é˜…è¯»ä»¥ä¸‹ç”¨æˆ·è¯„è®ºï¼Œè‡ªåŠ¨å½’çº³å‡ºå‰ 5 ä¸ªæœ€ä¸¥é‡çš„å…±æ€§é—®é¢˜ï¼ˆTopicï¼‰ã€‚

å¯¹äºæ¯ä¸ªé—®é¢˜ï¼Œè¯·æä¾›ï¼š
1. ç®€çŸ­çš„æ ‡é¢˜ï¼ˆå¦‚"ç”µæ± ç»­èˆªä¸è¶³"ã€"å®¢æœå“åº”æ…¢"ï¼‰
2. å±äºè¯¥é—®é¢˜çš„è¯„è®º ID åˆ—è¡¨
3. ä¸€å¥å…¸å‹çš„ç”¨æˆ·åŸè¯æ‘˜è¦

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ï¼š

{{
  "topics": [
    {{
      "topic": "é—®é¢˜æ ‡é¢˜",
      "review_ids": [1, 2, 3],
      "summary": "å…¸å‹ç”¨æˆ·åŸè¯æ‘˜è¦"
    }},
    {{
      "topic": "é—®é¢˜æ ‡é¢˜",
      "review_ids": [4, 5],
      "summary": "å…¸å‹ç”¨æˆ·åŸè¯æ‘˜è¦"
    }}
  ]
}}

ç”¨æˆ·è¯„è®ºï¼š
{reviews}

è¯·ç›´æ¥è¿”å› JSON æ ¼å¼ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—ï¼š"""
    
    try:
        # è°ƒç”¨ LLM
        prompt = prompt_template.format(reviews=all_reviews)
        response = llm.invoke(prompt)
        
        # æå–å›ç­”
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
        
        # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
        json_str = answer.strip()
        
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if json_str.startswith("```json"):
            json_str = json_str[7:]
        elif json_str.startswith("```"):
            json_str = json_str[3:]
        if json_str.endswith("```"):
            json_str = json_str[:-3]
        json_str = json_str.strip()
        
        # è§£æ JSON
        try:
            result = json.loads(json_str)
            topics = result.get('topics', [])
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            valid_topics = []
            for topic_data in topics:
                if 'topic' in topic_data and 'review_ids' in topic_data:
                    valid_topics.append({
                        'topic': topic_data['topic'],
                        'review_ids': topic_data['review_ids'] if isinstance(topic_data['review_ids'], list) else [],
                        'summary': topic_data.get('summary', '')
                    })
            
            return valid_topics
            
        except json.JSONDecodeError as e:
            st.warning(f"JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {e}")
            # å°è¯•æå– JSON å¯¹è±¡
            import re
            json_match = re.search(r'\{.*\}', json_str, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    return result.get('topics', [])
                except:
                    pass
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            st.error(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSONã€‚åŸå§‹å“åº”ï¼š\n{answer[:500]}")
            return []
            
    except Exception as e:
        st.error(f"LLM åˆ†æå‡ºé”™: {e}")
        return []


def convert_topics_to_aggregated_format(topics, reviews_df):
    """
    å°† LLM è¿”å›çš„ topics è½¬æ¢ä¸ºèšåˆæ ¼å¼ï¼Œä¾¿äº UI å±•ç¤º
    
    Args:
        topics: LLM è¿”å›çš„ topics åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« topic, review_ids, summary
        reviews_df: åŸå§‹è¯„è®º DataFrameï¼Œç”¨äºæ ¹æ® review_ids åæŸ¥è¯„è®ºå†…å®¹
    
    Returns:
        list: èšåˆåçš„æŠ±æ€¨åˆ—è¡¨ï¼Œæ ¼å¼ä¸åŸæ¥çš„ aggregate_complaints å…¼å®¹
    """
    aggregated = []
    
    # ç¡®ä¿ reviews_df æœ‰ review_id åˆ—
    if 'review_id' not in reviews_df.columns and 'user_id' in reviews_df.columns:
        reviews_df = reviews_df.copy()
        reviews_df['review_id'] = reviews_df['user_id']
    elif 'review_id' not in reviews_df.columns:
        reviews_df = reviews_df.copy()
        reviews_df['review_id'] = range(1, len(reviews_df) + 1)
    
    # æ”¶é›†æ‰€æœ‰å·²å½’ç±»çš„ review_idsï¼Œç”¨äºæ£€æµ‹é‡å¤å’Œé—æ¼
    all_classified_review_ids = set()
    
    for topic_data in topics:
        topic = topic_data.get('topic', 'æœªçŸ¥é—®é¢˜')
        review_ids = topic_data.get('review_ids', [])
        summary = topic_data.get('summary', '')
        
        # å»é‡ï¼šå¦‚æœåŒä¸€ä¸ª review_id å‡ºç°åœ¨å¤šä¸ª topics ä¸­ï¼Œåªä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„
        unique_review_ids = []
        for rid in review_ids:
            if rid not in all_classified_review_ids:
                unique_review_ids.append(rid)
                all_classified_review_ids.add(rid)
        
        # å¦‚æœå»é‡åæ²¡æœ‰æœ‰æ•ˆçš„ review_idsï¼Œè·³è¿‡è¿™ä¸ª topic
        if not unique_review_ids:
            continue
        
        # æ ¹æ® review_ids ä» DataFrame ä¸­åæŸ¥è¯„è®ºå†…å®¹
        reviews = []
        for rid in unique_review_ids:
            matching_rows = reviews_df[reviews_df['review_id'] == rid]
            if not matching_rows.empty:
                review_text = matching_rows.iloc[0].get('review_text', '') or matching_rows.iloc[0].get('content', '')
                if review_text:
                    reviews.append(review_text)
        
        aggregated.append({
            'complaint': topic,
            'count': len(unique_review_ids),  # ä½¿ç”¨å»é‡åçš„æ•°é‡
            'reviews': reviews,
            'summary': summary,
            'review_ids': unique_review_ids  # ä¿å­˜å»é‡åçš„ review_ids
        })
    
    # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åˆ—
    aggregated.sort(key=lambda x: x['count'], reverse=True)
    
    # éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„è´Ÿé¢è¯„è®º
    all_negative_review_ids = set(reviews_df['review_id'].tolist())
    unclassified_ids = all_negative_review_ids - all_classified_review_ids
    
    if unclassified_ids:
        # å¦‚æœæœ‰æœªå½’ç±»çš„è¯„è®ºï¼Œåˆ›å»ºä¸€ä¸ª"å…¶ä»–é—®é¢˜"ç±»åˆ«ï¼Œç¡®ä¿æ‰€æœ‰è¯„è®ºéƒ½è¢«ç»Ÿè®¡
        unclassified_reviews = []
        for rid in unclassified_ids:
            matching_rows = reviews_df[reviews_df['review_id'] == rid]
            if not matching_rows.empty:
                review_text = matching_rows.iloc[0].get('review_text', '') or matching_rows.iloc[0].get('content', '')
                if review_text:
                    unclassified_reviews.append(review_text)
        
        # åˆ›å»º"å…¶ä»–é—®é¢˜"ç±»åˆ«
        aggregated.append({
            'complaint': 'å…¶ä»–é—®é¢˜',
            'count': len(unclassified_ids),
            'reviews': unclassified_reviews,
            'summary': f'åŒ…å« {len(unclassified_ids)} æ¡æœªæ˜ç¡®å½’ç±»åˆ°ç‰¹å®šé—®é¢˜ç±»å‹çš„è´Ÿé¢è¯„è®º',
            'review_ids': list(unclassified_ids)
        })
        
        # é‡æ–°æ’åºï¼ˆå› ä¸ºæ·»åŠ äº†æ–°é¡¹ï¼‰
        aggregated.sort(key=lambda x: x['count'], reverse=True)
    
    return aggregated


def match_with_spec(complaint, qa_chain=None):
    """å°†ç”¨æˆ·æŠ±æ€¨ä¸äº§å“è¯´æ˜ä¹¦è¿›è¡ŒåŒ¹é…ï¼ˆä½¿ç”¨ RAGï¼‰"""
    
    # å¦‚æœæ²¡æœ‰ RAG é“¾ï¼Œä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…ä½œä¸ºåå¤‡
    if not qa_chain:
        if 'ä¸­æ–‡æ’­å®¢' in complaint or 'ä¸­æ–‡' in complaint:
            spec_match = "éŸ³é¢‘ä¸è¯­è¨€é™åˆ¶ï¼šAudio Overview ç›®å‰å¼ºè°ƒä¸ºå®éªŒæ€§åŠŸèƒ½...ä¸­æ–‡æ’­å®¢å¼è¾“å‡ºä½“éªŒæ˜æ˜¾å¼±äºè‹±æ–‡"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨ä¸­æ–‡æ”¯æŒæœ‰é™"
        elif 'PDF' in complaint or 'å›¾è¡¨' in complaint:
            spec_match = "å†…å®¹ä¸æ–‡ä»¶é™åˆ¶ï¼šå¯¹çº¯å›¾ç‰‡ PDFã€å¤æ‚è¡¨æ ¼æˆ–å›¾åƒä¿¡æ¯æ”¯æŒæœ‰é™ï¼Œå›¾è¡¨å’Œå›¾åƒå‹ PDF åœ¨è§£æå’Œæ£€ç´¢æ—¶ä»å¯èƒ½ä¸¢å¤±æˆ–å¼±åŒ–"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨å›¾è¡¨è§£æå—é™"
        else:
            spec_match = "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°å¯¹åº”æè¿°"
            conclusion = "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥ - å¯èƒ½æ˜¯æ–°å‘ç°çš„é—®é¢˜"
        return spec_match, conclusion, []
    
    # ä½¿ç”¨ RAG è¿›è¡ŒçœŸå®æ£€ç´¢å’Œåˆ†æ
    try:
        query = f"ç”¨æˆ·åé¦ˆï¼š{complaint}ã€‚è¯·åˆ†æè¿™æ˜¯äº§å“å·²çŸ¥å±€é™è¿˜æ˜¯æ–°é—®é¢˜ã€‚"
        answer, source_docs = perform_rag_query(qa_chain['vectorstore'], qa_chain['llm'], query)
        
        if not answer:
            raise Exception("RAG æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
        
        # è§£æå›ç­”ï¼Œæå–è¯´æ˜ä¹¦å‚æ•°å’Œç»“è®º
        spec_match = ""
        conclusion = ""
        
        # ä»å›ç­”ä¸­æå–ä¿¡æ¯
        if "è¯´æ˜ä¹¦å¯¹åº”å‚æ•°" in answer:
            parts = answer.split("è¯´æ˜ä¹¦å¯¹åº”å‚æ•°ï¼š")
            if len(parts) > 1:
                spec_part = parts[1].split("AI åˆ¤å®šç»“è®ºï¼š")[0].strip()
                spec_match = spec_part if spec_part else "æœªæ‰¾åˆ°ç›¸å…³è¯´æ˜"
        else:
            spec_match = "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°å¯¹åº”æè¿°"
        
        if "AI åˆ¤å®šç»“è®º" in answer:
            conclusion = answer.split("AI åˆ¤å®šç»“è®ºï¼š")[-1].strip()
        else:
            # ä»å›ç­”ä¸­æ¨æ–­ç»“è®º
            if "å·²çŸ¥å±€é™" in answer or "âœ…" in answer:
                conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - " + answer[:50]
            elif "æ–°é—®é¢˜" in answer or "âš ï¸" in answer:
                conclusion = "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥ - " + answer[:50]
            else:
                conclusion = "â“ éœ€è¦äººå·¥åˆ¤æ–­ - " + answer[:50]
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°ï¼Œä½¿ç”¨æºæ–‡æ¡£å†…å®¹
        if not spec_match and source_docs:
            spec_match = "\n\n".join([doc.page_content[:200] + "..." for doc in source_docs[:2]])
        
        # è¿”å›æºæ–‡æ¡£å†…å®¹ç”¨äºå±•ç¤ºï¼ˆå»é‡ï¼‰
        source_contents = []
        seen_contents = set()
        for doc in source_docs:
            content = doc.page_content
            # ä½¿ç”¨å‰100ä¸ªå­—ç¬¦ä½œä¸ºæŒ‡çº¹å»é‡
            fingerprint = content[:100].strip()
            if fingerprint not in seen_contents:
                seen_contents.add(fingerprint)
                source_contents.append(content)
        
        return spec_match, conclusion, source_contents
        
    except Exception as e:
        st.warning(f"RAG åˆ†æå‡ºé”™: {e}ï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ")
        # åå¤‡æ–¹æ¡ˆ
        if 'ä¸­æ–‡æ’­å®¢' in complaint or 'ä¸­æ–‡' in complaint:
            spec_match = "éŸ³é¢‘ä¸è¯­è¨€é™åˆ¶ï¼šAudio Overview ç›®å‰å¼ºè°ƒä¸ºå®éªŒæ€§åŠŸèƒ½...ä¸­æ–‡æ’­å®¢å¼è¾“å‡ºä½“éªŒæ˜æ˜¾å¼±äºè‹±æ–‡"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨ä¸­æ–‡æ”¯æŒæœ‰é™"
        elif 'PDF' in complaint or 'å›¾è¡¨' in complaint:
            spec_match = "å†…å®¹ä¸æ–‡ä»¶é™åˆ¶ï¼šå¯¹çº¯å›¾ç‰‡ PDFã€å¤æ‚è¡¨æ ¼æˆ–å›¾åƒä¿¡æ¯æ”¯æŒæœ‰é™ï¼Œå›¾è¡¨å’Œå›¾åƒå‹ PDF åœ¨è§£æå’Œæ£€ç´¢æ—¶ä»å¯èƒ½ä¸¢å¤±æˆ–å¼±åŒ–"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨å›¾è¡¨è§£æå—é™"
        else:
            spec_match = "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°å¯¹åº”æè¿°"
            conclusion = "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥ - å¯èƒ½æ˜¯æ–°å‘ç°çš„é—®é¢˜"
        return spec_match, conclusion, []


def generate_ai_brief(df, negative_ratio):
    """ç”Ÿæˆ AI æ¯æ—¥ç®€æŠ¥ï¼ˆåŸºäºå®é™…ç”¨æˆ·åé¦ˆæ•°æ®ï¼‰"""
    # ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼šæ­£é¢ + è´Ÿé¢ + ä¸­æ€§ = æ€»æ•°
    negative_count = len(df[df['rating'] < 3])  # rating < 3: è´Ÿé¢
    positive_count = len(df[df['rating'] >= 4])  # rating >= 4: æ­£é¢
    neutral_count = len(df[df['rating'] == 3])   # rating == 3: ä¸­æ€§
    
    # éªŒè¯æ•°æ®ä¸€è‡´æ€§
    total_calculated = positive_count + negative_count + neutral_count
    if total_calculated != len(df):
        # å¦‚æœæ•°æ®ä¸ä¸€è‡´ï¼Œé‡æ–°è®¡ç®—ï¼ˆå¤„ç†å¯èƒ½çš„ NaN æˆ–å…¶ä»–å¼‚å¸¸å€¼ï¼‰
        negative_count = len(df[df['rating'] < 3].dropna())
        positive_count = len(df[df['rating'] >= 4].dropna())
        neutral_count = len(df[df['rating'] == 3].dropna())
    
    # å¦‚æœå·²æœ‰åˆ†æç»“æœï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨é€šç”¨æè¿°
    if 'analysis_topics' in st.session_state:
        topics = st.session_state['analysis_topics']
        top_issues = [t.get('topic', '') for t in topics[:3]]
        top_issue_text = "ã€".join([f"**{issue}**" for issue in top_issues[:2] if issue])
    else:
        top_issue_text = "åŠŸèƒ½ä½¿ç”¨é—®é¢˜"
    
    # æ„å»ºåé¦ˆç»Ÿè®¡æ–‡æœ¬ï¼ˆæ ¹æ®æ˜¯å¦æœ‰ä¸­æ€§è¯„ä»·å†³å®šæ˜¾ç¤ºæ ¼å¼ï¼‰
    if neutral_count > 0:
        feedback_summary = f"æœ¬å‘¨å…±æ”¶é›† **{len(df)}** æ¡ç”¨æˆ·åé¦ˆï¼Œå…¶ä¸­æ­£å‘è¯„ä»· **{positive_count}** æ¡ï¼Œè´Ÿå‘è¯„ä»· **{negative_count}** æ¡ï¼Œä¸­æ€§è¯„ä»· **{neutral_count}** æ¡"
    else:
        feedback_summary = f"æœ¬å‘¨å…±æ”¶é›† **{len(df)}** æ¡ç”¨æˆ·åé¦ˆï¼Œå…¶ä¸­æ­£å‘è¯„ä»· **{positive_count}** æ¡ï¼Œè´Ÿå‘è¯„ä»· **{negative_count}** æ¡"
    
    brief = f"""
### ğŸ“Š èˆ†æƒ…è¶‹åŠ¿åˆ†æ

**æ•´ä½“æƒ…ç»ªï¼š** {"ğŸ˜Š æ­£å‘ä¸ºä¸»" if negative_ratio < 30 else "ğŸ˜ ä¸­æ€§åè´Ÿ" if negative_ratio < 50 else "ğŸ˜Ÿ è´Ÿå‘é¢„è­¦"}

**æ ¸å¿ƒå‘ç°ï¼š**
- {feedback_summary}
- ç”¨æˆ·åé¦ˆä¸»è¦é›†ä¸­åœ¨ **äº§å“åŠŸèƒ½é™åˆ¶è¯´æ˜ä¸æ¸…** å’Œ **å®é™…æ€§èƒ½ä¸å®£ä¼ å‚æ•°ä¸ç¬¦** ä¸¤å¤§æ–¹é¢
- å½“å‰æœ€çªå‡ºçš„é—®é¢˜ç±»å‹ï¼š{top_issue_text if top_issue_text else "åŠŸèƒ½ä½¿ç”¨é—®é¢˜"}

**èˆ†æƒ…é¢„è­¦ï¼š**
- ğŸ”´ æ–°æ‰‹ç”¨æˆ·å¯¹äº§å“é™åˆ¶æ¡ä»¶çš„è®¤çŸ¥ä¸è¶³ï¼Œå¯¼è‡´ä½¿ç”¨ä½“éªŒå·®
- ğŸŸ¡ ç¡¬ä»¶è´¨é‡é—®é¢˜å½±å“ç”¨æˆ·å¯¹äº§å“å“è´¨çš„ä¿¡ä»»
- ğŸŸ¡ è¯´æ˜ä¹¦å¯è¯»æ€§ä¸è¶³ï¼Œç”¨æˆ·éš¾ä»¥å¿«é€Ÿç†è§£å…³é”®é™åˆ¶æ¡ä»¶

**å»ºè®®å…³æ³¨ï¼š**
- ä¼˜åŒ–äº§å“è¯´æ˜ä¹¦ï¼Œçªå‡ºå…³é”®é™åˆ¶æ¡ä»¶
- åŠ å¼ºæ–°æ‰‹å¼•å¯¼ï¼Œåœ¨äº§å“é¦–æ¬¡ä½¿ç”¨æ—¶ä¸»åŠ¨æç¤ºé‡è¦é™åˆ¶
- å…³æ³¨ç¡¬ä»¶å“æ§ï¼Œå‡å°‘è´¨é‡é—®é¢˜
"""
    return brief


# ==================== Action Plan æ•°æ®ç»“æ„ ====================
class ActionType(str, Enum):
    """è¡ŒåŠ¨ç±»å‹æšä¸¾"""
    JIRA_TICKET = "Jira Ticket"
    DOC_UPDATE = "Doc Update"
    EMAIL_DRAFT = "Email Draft"
    MEETING = "Meeting"


class Priority(str, Enum):
    """ä¼˜å…ˆçº§æšä¸¾"""
    HIGH = "High"
    MEDIUM = "Medium"
    LOW = "Low"


if PYDANTIC_AVAILABLE:
    class ActionPlan(BaseModel):
        """è¡ŒåŠ¨è®¡åˆ’æ•°æ®æ¨¡å‹"""
        action_type: ActionType
        title: str
        content: str
        priority: Priority
        
        model_config = ConfigDict(use_enum_values=True)
else:
    # å¦‚æœæ²¡æœ‰ Pydanticï¼Œä½¿ç”¨å­—å…¸ç»“æ„
    ActionPlan = dict


def render_case_group(rag_result, action_item, batch_idx=0, item_idx=0):
    """
    æˆç»„æ¸²æŸ“å•ä¸ª Caseï¼šåŒ…å« RAG å½’å› åˆ†æ + å¯¹åº”çš„è¡ŒåŠ¨å»ºè®®
    é‡‡ç”¨ Case-Based å¸ƒå±€ï¼Œå½¢æˆå®Œæ•´çš„è¯æ®é“¾é—­ç¯
    """
    review_id = rag_result.get("review_id", f"æœªçŸ¥_{item_idx}")
    review_text = rag_result.get("review_text", "")
    conclusion = rag_result.get("conclusion", "â“ éœ€è¦äººå·¥åˆ¤æ–­")
    reason = rag_result.get("reason", "")
    evidence = rag_result.get("evidence", "")
    
    # æ ¹æ®ç»“è®ºç±»å‹è®¾ç½®é¢œè‰²ã€å›¾æ ‡å’Œè§†è§‰æ ·å¼
    if "äº§å“ç¼ºé™·" in conclusion or "âš ï¸" in conclusion or "éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" in conclusion:
        # æƒ…å†µ Aï¼šäº§å“ç¼ºé™·
        conclusion_type = "äº§å“ç¼ºé™·"
        card_style = "error"
        title_prefix = "ğŸ”´ [äº§å“ç¼ºé™·]"
        container_func = st.error
    elif "ç”¨æˆ·" in conclusion or "â“" in conclusion or "ç”¨æˆ·ä½¿ç”¨é—®é¢˜" in conclusion:
        # æƒ…å†µ Bï¼šç”¨æˆ·è¯¯è§£/æ“ä½œä¸å½“
        conclusion_type = "ç”¨æˆ·è¯¯è§£"
        card_style = "warning"
        title_prefix = "âš ï¸ [ç”¨æˆ·è¯¯è§£]"
        container_func = st.warning
    elif "âœ…" in conclusion or "äº§å“å·²çŸ¥å±€é™" in conclusion:
        # æƒ…å†µ Cï¼šäº§å“å·²çŸ¥å±€é™
        conclusion_type = "äº§å“å·²çŸ¥å±€é™"
        card_style = "info"
        title_prefix = "â„¹ï¸ [äº§å“å·²çŸ¥å±€é™]"
        container_func = st.info
    else:
        # å…¶ä»–æƒ…å†µ
        conclusion_type = "å…¶ä»–é—®é¢˜"
        card_style = "info"
        title_prefix = "ğŸ”µ [å…¶ä»–é—®é¢˜]"
        container_func = st.info
    
    # æå–é—®é¢˜æ ‡é¢˜
    title_keywords = ["ç»­èˆª", "é¿éšœ", "äº‘å°", "æŠ–åŠ¨", "ç”µæ± ", "å›¾ä¼ ", "GPS", "è™šæ ‡", "ç¡¬ä»¶", "è‡ªæ£€"]
    title = "æœªçŸ¥é—®é¢˜"
    for keyword in title_keywords:
        if keyword in review_text:
            title = keyword + "ç›¸å…³é—®é¢˜"
            break
    
    # ç”Ÿæˆå”¯ä¸€çš„ key
    unique_key = f"case_{batch_idx}_{item_idx}_{review_id}"
    
    # åˆ›å»ºå®Œæ•´çš„ Case å®¹å™¨ï¼ˆä½¿ç”¨ border=True å¢å¼ºè§†è§‰åˆ†ç»„ï¼‰
    with st.container(border=True):
        # 1. Header: é£é™©æ ‡é¢˜ - ä¼˜åŒ–æ˜¾ç¤ºï¼Œé¿å…é‡å¤å›¾æ ‡
        st.markdown("")  # æ·»åŠ é¡¶éƒ¨é—´è·
        
        # æå–å›¾æ ‡å’Œæ–‡æœ¬ï¼ˆtitle_prefix å·²ç»åŒ…å«å›¾æ ‡ï¼Œä¸éœ€è¦é‡å¤æ˜¾ç¤ºï¼‰
        # ä¾‹å¦‚ï¼štitle_prefix = "ğŸ”´ [äº§å“ç¼ºé™·]" æˆ– "â„¹ï¸ [äº§å“å·²çŸ¥å±€é™]"
        st.markdown(f"### {title_prefix} {title}")
        st.caption(f"ğŸ“‹ è¯„è®ºID: {review_id}")
        
        st.markdown("---")  # æ·»åŠ åˆ†éš”çº¿ï¼Œæ›´æ¸…æ™°
        
        # 2. Section 1: å½’å› åˆ†æ (Evidence) - ä¼˜åŒ–å¸ƒå±€
        st.markdown("#### ğŸ” å½’å› åˆ†æ")
        st.markdown("")  # æ·»åŠ å°é—´è·
        
        col_left, col_mid, col_right = st.columns([1, 1, 1])
        
        with col_left:
            st.markdown("**ğŸ’¬ ç”¨æˆ·åŸè¯**")
            st.markdown("")  # å°é—´è·
            # ä½¿ç”¨æ›´å‹å¥½çš„æ˜¾ç¤ºæ–¹å¼
            with st.container():
                container_func(review_text)
        
        with col_mid:
            st.markdown("**ğŸ“– RAG è¯æ®**")
            st.markdown("")  # å°é—´è·
            if evidence and evidence not in ["æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°", "å‘é‡åº“æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ", ""]:
                if len(evidence) > 500:
                    with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯æ®", expanded=False):
                        st.markdown(evidence)
                    with st.container():
                        container_func(evidence[:500] + "...")
                else:
                    with st.container():
                        container_func(evidence)
            elif evidence == "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°":
                st.warning("âš ï¸ æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°")
            else:
                st.warning("âš ï¸ å‘é‡æ£€ç´¢æœªå¯ç”¨æˆ–å¤±è´¥")
        
        with col_right:
            st.markdown("**ğŸ¤– AI åˆ¤å®š**")
            st.markdown("")  # å°é—´è·
            with st.container():
                # ä¼˜åŒ–ç»“è®ºæ˜¾ç¤º
                conclusion_text = conclusion.replace("**ç»“è®ºï¼š**", "").strip()
                container_func(f"**ç»“è®ºï¼š** {conclusion_text}")
                st.markdown("")  # å°é—´è·
                # ä¼˜åŒ–åˆ†ææ˜¾ç¤º
                analysis_text = reason if reason else 'æš‚æ— è¯¦ç»†åˆ†æ'
                st.markdown(f"**åˆ†æï¼š** {analysis_text}")
        
        # 3. Section 2: å†³ç­–è½åœ° (Action) - ç¡®ä¿å§‹ç»ˆæ˜¾ç¤º
        st.divider()  # ä½¿ç”¨åˆ†å‰²çº¿æ¸…æ™°åŒºåˆ†åˆ†æä¸è¡ŒåŠ¨
        st.markdown("##### ğŸ’¡ å†³ç­–è½åœ°")
        
        if action_item and action_item.get("title"):
            # æœ‰ action æ•°æ®ï¼Œæ­£å¸¸æ˜¾ç¤º
            action_type = action_item.get("action_type", "Jira Ticket")
            action_title = action_item.get("title", "")
            action_content = action_item.get("content", "")
            priority = action_item.get("priority", "Medium")
            
            # ä¼˜å…ˆçº§é¢œè‰²
            priority_colors = {
                "High": "ğŸ”´",
                "Medium": "ğŸŸ¡",
                "Low": "ğŸŸ¢"
            }
            priority_icon = priority_colors.get(priority, "ğŸŸ¡")
            
            # è¡ŒåŠ¨ç±»å‹å›¾æ ‡
            type_icons = {
                "Jira Ticket": "ğŸ",
                "Doc Update": "ğŸ“",
                "Email Draft": "ğŸ“§",
                "Meeting": "ğŸ“…"
            }
            type_icon = type_icons.get(action_type, "ğŸ“‹")
            
            # æ˜¾ç¤ºè¡ŒåŠ¨å»ºè®®ä¿¡æ¯
            st.markdown(f"**{type_icon} {action_title}** Â· {priority_icon} {priority} Â· {action_type}")
            
            # æ˜¾ç¤ºå†…å®¹
            if action_content:
                if len(action_content) > 500:
                    with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´å†…å®¹", expanded=False):
                        st.markdown(action_content)
                    st.markdown(action_content[:500] + "...")
                else:
                    st.markdown(action_content)
            else:
                st.info("ğŸ“ è¡ŒåŠ¨å»ºè®®å†…å®¹ç”Ÿæˆä¸­...")
            
            # Mock æŒ‰é’®ï¼ˆæ ¹æ®ç±»å‹ä½¿ç”¨ä¸åŒæ ·å¼ï¼‰
            col_btn1, col_btn2 = st.columns([1, 1])
            with col_btn1:
                if action_type == "Jira Ticket":
                    if st.button("ğŸš€ æ¨é€è‡³ Jira", key=f"action_jira_{unique_key}", use_container_width=True, type="primary"):
                        import random
                        ticket_id = f"DJI-2025-{random.randint(1000, 9999)}"
                        st.toast(f"âœ… å·¥å•å·²åˆ›å»ºï¼Ticket ID: {ticket_id}", icon="ğŸ‰")
                elif action_type == "Doc Update":
                    if st.button("ğŸ“ åˆ›å»º Notion Task", key=f"action_notion_{unique_key}", use_container_width=True):
                        st.toast("âœ… Notion ä»»åŠ¡å·²åˆ›å»ºï¼", icon="ğŸ‰")
                elif action_type == "Email Draft":
                    if st.button("ğŸ“§ å¤åˆ¶é‚®ä»¶", key=f"action_email_{unique_key}", use_container_width=True):
                        st.toast("âœ… é‚®ä»¶å†…å®¹å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼", icon="ğŸ‰")
                elif action_type == "Meeting":
                    if st.button("ğŸ“… åˆ›å»ºä¼šè®®", key=f"action_meeting_{unique_key}", use_container_width=True):
                        st.toast("âœ… ä¼šè®®å·²åˆ›å»ºï¼", icon="ğŸ‰")
        else:
            # æ²¡æœ‰ action æ•°æ®ï¼Œæ˜¾ç¤ºå‹å¥½çš„å ä½ç¬¦
            st.warning("âš ï¸ **æš‚æœªç”Ÿæˆå¯¹åº”çš„è¡ŒåŠ¨å»ºè®®**")
            st.info("ğŸ’¡ ç³»ç»Ÿæ­£åœ¨åˆ†æä¸­ï¼Œè¡ŒåŠ¨å»ºè®®å°†æ ¹æ®å½’å› ç»“æœè‡ªåŠ¨ç”Ÿæˆã€‚")
            
            # æä¾›æ‰‹åŠ¨åˆ›å»ºæŒ‰é’®
            with st.expander("ğŸ”§ æ‰‹åŠ¨åˆ›å»ºè¡ŒåŠ¨å»ºè®®", expanded=False):
                action_type_manual = st.selectbox(
                    "è¡ŒåŠ¨ç±»å‹",
                    ["Jira Ticket", "Doc Update", "Email Draft", "Meeting"],
                    key=f"manual_action_type_{unique_key}"
                )
                action_title_manual = st.text_input(
                    "æ ‡é¢˜",
                    value=f"å¤„ç† {review_id} çš„é—®é¢˜",
                    key=f"manual_action_title_{unique_key}"
                )
                action_content_manual = st.text_area(
                    "å†…å®¹",
                    value=f"ç”¨æˆ·åé¦ˆï¼š{review_text[:200]}...",
                    height=100,
                    key=f"manual_action_content_{unique_key}"
                )
                if st.button("âœ… åˆ›å»ºè¡ŒåŠ¨å»ºè®®", key=f"manual_action_create_{unique_key}"):
                    st.success("âœ… è¡ŒåŠ¨å»ºè®®å·²åˆ›å»ºï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
                    st.toast("âœ… è¡ŒåŠ¨å»ºè®®å·²åˆ›å»ºï¼", icon="ğŸ‰")


def render_rag_card(rag_result, batch_idx=0, item_idx=0):
    """æ¸²æŸ“å•ä¸ª RAG å½’å› åˆ†æå¡ç‰‡"""
    review_id = rag_result.get("review_id", f"æœªçŸ¥_{item_idx}")
    review_text = rag_result.get("review_text", "")
    conclusion = rag_result.get("conclusion", "â“ éœ€è¦äººå·¥åˆ¤æ–­")
    reason = rag_result.get("reason", "")
    evidence = rag_result.get("evidence", "")
    
    # æ ¹æ®ç»“è®ºç±»å‹è®¾ç½®é¢œè‰²ã€å›¾æ ‡å’Œè§†è§‰æ ·å¼
    if "äº§å“ç¼ºé™·" in conclusion or "âš ï¸" in conclusion or "éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" in conclusion:
        # æƒ…å†µ Aï¼šäº§å“ç¼ºé™·
        conclusion_type = "äº§å“ç¼ºé™·"
        card_style = "error"
        title_prefix = "ğŸ”´ [äº§å“ç¼ºé™·]"
    elif "ç”¨æˆ·" in conclusion or "â“" in conclusion or "ç”¨æˆ·ä½¿ç”¨é—®é¢˜" in conclusion:
        # æƒ…å†µ Bï¼šç”¨æˆ·è¯¯è§£/æ“ä½œä¸å½“
        conclusion_type = "ç”¨æˆ·è¯¯è§£"
        card_style = "warning"
        title_prefix = "âš ï¸ [ç”¨æˆ·è¯¯è§£]"
    elif "âœ…" in conclusion or "äº§å“å·²çŸ¥å±€é™" in conclusion:
        # æƒ…å†µ Cï¼šäº§å“å·²çŸ¥å±€é™
        conclusion_type = "äº§å“å·²çŸ¥å±€é™"
        card_style = "info"
        title_prefix = "â„¹ï¸ [äº§å“å·²çŸ¥å±€é™]"
    else:
        # å…¶ä»–æƒ…å†µ
        conclusion_type = "å…¶ä»–é—®é¢˜"
        card_style = "info"
        title_prefix = "ğŸ”µ [å…¶ä»–é—®é¢˜]"
    
    # æå–é—®é¢˜æ ‡é¢˜
    title_keywords = ["ç»­èˆª", "é¿éšœ", "äº‘å°", "æŠ–åŠ¨", "ç”µæ± ", "å›¾ä¼ ", "GPS", "è™šæ ‡", "ç¡¬ä»¶", "è‡ªæ£€"]
    title = "æœªçŸ¥é—®é¢˜"
    for keyword in title_keywords:
        if keyword in review_text:
            title = keyword + "ç›¸å…³é—®é¢˜"
            break
    
    # ç”Ÿæˆå”¯ä¸€çš„ keyï¼ˆé¿å…ä¸åŒæ‰¹æ¬¡é—´çš„ key å†²çªï¼‰
    unique_key = f"rag_{batch_idx}_{item_idx}_{review_id}"
    
    # ä½¿ç”¨ä¸åŒæ ·å¼å±•ç¤ºå¡ç‰‡
    if card_style == "error":
        with st.expander(f"{title_prefix} {title} (ID: {review_id})", expanded=(batch_idx == 0 and item_idx == 0)):
            col_left, col_mid, col_right = st.columns([1, 1, 1])
            
            with col_left:
                st.markdown("##### ğŸ’¬ ç”¨æˆ·åŸè¯")
                st.error(review_text)
            
            with col_mid:
                st.markdown("##### ğŸ“– RAG è¯æ®")
                if evidence and evidence not in ["æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°", "å‘é‡åº“æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ", ""]:
                    if len(evidence) > 500:
                        with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯æ®", expanded=False):
                            st.markdown(evidence)
                        st.error(evidence[:500] + "...")
                    else:
                        st.error(evidence)
                elif evidence == "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°":
                    st.warning("âš ï¸ æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°")
                else:
                    st.warning("âš ï¸ å‘é‡æ£€ç´¢æœªå¯ç”¨æˆ–å¤±è´¥")
            
            with col_right:
                st.markdown("##### ğŸ¤– AI åˆ¤å®š")
                st.error(f"**ç»“è®ºï¼š** {conclusion}")
                st.markdown(f"**åˆ†æï¼š** {reason if reason else 'æš‚æ— è¯¦ç»†åˆ†æ'}")
    elif card_style == "warning":
        with st.expander(f"{title_prefix} {title} (ID: {review_id})", expanded=(batch_idx == 0 and item_idx == 0)):
            col_left, col_mid, col_right = st.columns([1, 1, 1])
            
            with col_left:
                st.markdown("##### ğŸ’¬ ç”¨æˆ·åŸè¯")
                st.warning(review_text)
            
            with col_mid:
                st.markdown("##### ğŸ“– RAG è¯æ®")
                if evidence and evidence not in ["æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°", "å‘é‡åº“æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ", ""]:
                    if len(evidence) > 500:
                        with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯æ®", expanded=False):
                            st.markdown(evidence)
                        st.warning(evidence[:500] + "...")
                    else:
                        st.warning(evidence)
                elif evidence == "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°":
                    st.info("â„¹ï¸ æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°")
                else:
                    st.info("â„¹ï¸ å‘é‡æ£€ç´¢æœªå¯ç”¨æˆ–å¤±è´¥")
            
            with col_right:
                st.markdown("##### ğŸ¤– AI åˆ¤å®š")
                st.warning(f"**ç»“è®ºï¼š** {conclusion}")
                st.markdown(f"**åˆ†æï¼š** {reason if reason else 'æš‚æ— è¯¦ç»†åˆ†æ'}")
    else:
        with st.expander(f"{title_prefix} {title} (ID: {review_id})", expanded=(batch_idx == 0 and item_idx == 0)):
            col_left, col_mid, col_right = st.columns([1, 1, 1])
            
            with col_left:
                st.markdown("##### ğŸ’¬ ç”¨æˆ·åŸè¯")
                st.info(review_text)
            
            with col_mid:
                st.markdown("##### ğŸ“– RAG è¯æ®")
                if evidence and evidence not in ["æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°", "å‘é‡åº“æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ", ""]:
                    if len(evidence) > 500:
                        with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯æ®", expanded=False):
                            st.markdown(evidence)
                        st.info(evidence[:500] + "...")
                    else:
                        st.info(evidence)
                elif evidence == "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°":
                    st.info("â„¹ï¸ æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°")
                else:
                    st.info("â„¹ï¸ å‘é‡æ£€ç´¢æœªå¯ç”¨æˆ–å¤±è´¥")
            
            with col_right:
                st.markdown("##### ğŸ¤– AI åˆ¤å®š")
                st.info(f"**ç»“è®ºï¼š** {conclusion}")
                st.markdown(f"**åˆ†æï¼š** {reason if reason else 'æš‚æ— è¯¦ç»†åˆ†æ'}")


def render_action_card(action, batch_idx=0, item_idx=0):
    """æ¸²æŸ“å•ä¸ªè¡ŒåŠ¨å»ºè®®å¡ç‰‡"""
    action_type = action.get("action_type", "Jira Ticket")
    title = action.get("title", "")
    content = action.get("content", "")
    priority = action.get("priority", "Medium")
    
    # ä¼˜å…ˆçº§é¢œè‰²
    priority_colors = {
        "High": "ğŸ”´",
        "Medium": "ğŸŸ¡",
        "Low": "ğŸŸ¢"
    }
    priority_icon = priority_colors.get(priority, "ğŸŸ¡")
    
    # è¡ŒåŠ¨ç±»å‹å›¾æ ‡
    type_icons = {
        "Jira Ticket": "ğŸ",
        "Doc Update": "ğŸ“",
        "Email Draft": "ğŸ“§",
        "Meeting": "ğŸ“…"
    }
    type_icon = type_icons.get(action_type, "ğŸ“‹")
    
    # ç”Ÿæˆå”¯ä¸€çš„ keyï¼ˆç”¨äºå…¶ä»–ç»„ä»¶çš„ keyï¼Œä½† st.expander ä¸æ”¯æŒ key å‚æ•°ï¼‰
    unique_key = f"action_{batch_idx}_{item_idx}_{action.get('review_id', item_idx)}"
    
    with st.expander(f"{type_icon} **{title}** Â· {priority_icon} {priority} Â· {action_type}", expanded=(batch_idx == 0 and item_idx <= 1)):
        st.markdown(f"**ä¼˜å…ˆçº§ï¼š** {priority}")
        st.markdown(f"**ç±»å‹ï¼š** {action_type}")
        st.markdown(f"**å†…å®¹ï¼š**")
        if len(content) > 500:
            st.text_area("", value=content, height=150, disabled=True, key=f"action_content_{unique_key}", label_visibility="collapsed")
        else:
            st.markdown(content)
        
        # Mock æŒ‰é’®ï¼ˆæ ¹æ®ç±»å‹ä½¿ç”¨ä¸åŒæ ·å¼ï¼‰
        if action_type == "Jira Ticket":
            if st.button("ğŸš€ æ¨é€è‡³ Jira", key=f"action_jira_{unique_key}", use_container_width=True, type="primary"):
                import random
                ticket_id = f"DJI-2025-{random.randint(1000, 9999)}"
                st.toast(f"âœ… å·¥å•å·²åˆ›å»ºï¼Ticket ID: {ticket_id}", icon="ğŸ‰")
        elif action_type == "Doc Update":
            if st.button("ğŸ“ åˆ›å»º Notion Task", key=f"action_notion_{unique_key}", use_container_width=True):
                st.toast("âœ… Notion ä»»åŠ¡å·²åˆ›å»ºï¼", icon="ğŸ‰")
        elif action_type == "Email Draft":
            if st.button("ğŸ“§ å¤åˆ¶é‚®ä»¶", key=f"action_email_{unique_key}", use_container_width=True):
                st.toast("âœ… é‚®ä»¶å†…å®¹å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼", icon="ğŸ‰")
        elif action_type == "Meeting":
            if st.button("ğŸ“… åˆ›å»ºä¼šè®®", key=f"action_meeting_{unique_key}", use_container_width=True):
                st.toast("âœ… ä¼šè®®å·²åˆ›å»ºï¼", icon="ğŸ‰")


def generate_action_plan(topic_name: str, rag_conclusion: str, user_complaints: list, llm) -> Optional[dict]:
    """
    ä½¿ç”¨ LLM æ ¹æ® RAG åˆ†æç»“æœåŠ¨æ€ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’
    
    Args:
        topic_name: é—®é¢˜èšç±»åç§°
        rag_conclusion: RAG åˆ†æå‡ºçš„å½’å› ç»“è®º
        user_complaints: å…¸å‹ç”¨æˆ·åŸè¯åˆ—è¡¨
        llm: LangChain LLM å®ä¾‹
    
    Returns:
        dict: ActionPlan å¯¹è±¡ï¼ˆåŒ…å« action_type, title, content, priorityï¼‰
    """
    if not llm:
        return None
    
    # æ„å»ºç”¨æˆ·æŠ±æ€¨æ‘˜è¦
    complaints_text = "\n".join([f"- {complaint}" for complaint in user_complaints[:5]])
    
    # æ„å»º Prompt
    prompt_template = """ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®é—®é¢˜æ€§è´¨åšå‡ºå†³ç­–çš„äº§å“ç»ç†ã€‚

è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’ï¼š

**é—®é¢˜ç±»å‹ï¼š** {topic_name}

**RAG å½’å› ç»“è®ºï¼š** {rag_conclusion}

**å…¸å‹ç”¨æˆ·åé¦ˆï¼š**
{complaints}

**å†³ç­–è§„åˆ™ï¼š**
- å¦‚æœå½’å› æ˜¯ **äº§å“ç¼ºé™·/Bug** -> ç”Ÿæˆ Jira Ticketï¼ŒåŒ…å«æ ‡é¢˜ã€æè¿°ã€å¤ç°æ­¥éª¤ã€ä¼˜å…ˆçº§
- å¦‚æœå½’å› æ˜¯ **ç”¨æˆ·è¯¯æ“ä½œ/æ–‡æ¡£ä¸æ¸…** -> ç”Ÿæˆ Doc Updateï¼ˆæ›´æ–°è¯´æ˜ä¹¦ï¼‰æˆ– Email Draftï¼ˆå®¢æœè¯æœ¯ï¼‰
- å¦‚æœå½’å› æ˜¯ **ç‰©æµ/æœåŠ¡é—®é¢˜** -> ç”Ÿæˆ Email Draftï¼ˆç»™ç‰©æµå•†æˆ–å®¢æœä¸»ç®¡ï¼‰
- å¦‚æœå½’å› æ˜¯ **å¤æ‚é—®é¢˜éœ€è¦è®¨è®º** -> ç”Ÿæˆ Meetingï¼ˆä¼šè®®å®‰æ’ï¼‰

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ï¼š

{{
  "action_type": "Jira Ticket" | "Doc Update" | "Email Draft" | "Meeting",
  "title": "è¡ŒåŠ¨çš„ç®€çŸ­æ ‡é¢˜ï¼ˆå¦‚ï¼šåˆ›å»º P0 çº§ Jira å·¥å•ï¼šä¿®å¤äº‘å°æŠ–åŠ¨ï¼‰",
  "content": "è¡ŒåŠ¨çš„è¯¦ç»†å†…å®¹ï¼ˆå¦‚å·¥å•çš„ Description æˆ–é‚®ä»¶çš„æ­£æ–‡ï¼Œè¦å…·ä½“å¯æ‰§è¡Œï¼‰",
  "priority": "High" | "Medium" | "Low"
}}

è¯·ç›´æ¥è¿”å› JSON æ ¼å¼ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—ï¼š"""
    
    try:
        prompt = prompt_template.format(
            topic_name=topic_name,
            rag_conclusion=rag_conclusion,
            complaints=complaints_text
        )
        
        response = llm.invoke(prompt)
        
        # æå–å›ç­”
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
        
        # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
        json_str = answer.strip()
        
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if json_str.startswith("```json"):
            json_str = json_str[7:]
        elif json_str.startswith("```"):
            json_str = json_str[3:]
        if json_str.endswith("```"):
            json_str = json_str[:-3]
        json_str = json_str.strip()
        
        # è§£æ JSON
        try:
            result = json.loads(json_str)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['action_type', 'title', 'content', 'priority']
            if all(field in result for field in required_fields):
                # éªŒè¯ action_type
                valid_types = ['Jira Ticket', 'Doc Update', 'Email Draft', 'Meeting']
                if result['action_type'] not in valid_types:
                    result['action_type'] = 'Doc Update'  # é»˜è®¤å€¼
                
                # éªŒè¯ priority
                valid_priorities = ['High', 'Medium', 'Low']
                if result['priority'] not in valid_priorities:
                    result['priority'] = 'Medium'  # é»˜è®¤å€¼
                
                return result
            else:
                st.warning(f"LLM è¿”å›çš„ JSON ç¼ºå°‘å¿…éœ€å­—æ®µã€‚åŸå§‹å“åº”ï¼š\n{answer[:500]}")
                return None
                
        except json.JSONDecodeError as e:
            st.warning(f"JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {e}")
            # å°è¯•æå– JSON å¯¹è±¡
            json_match = re.search(r'\{.*\}', json_str, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    return result
                except:
                    pass
            
            st.error(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSONã€‚åŸå§‹å“åº”ï¼š\n{answer[:500]}")
            return None
            
    except Exception as e:
        st.error(f"ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’æ—¶å‡ºé”™: {e}")
        return None


# ==================== ä¾§è¾¹æ  ====================
with st.sidebar:
    st.markdown("## ğŸ”¬ ReviewOps")
    st.markdown("*ç”¨æˆ·åé¦ˆå†³ç­–ä¸­å°*")
    
    st.divider()
    
    # äº§å“ä¿¡æ¯
    product_name = extract_product_name()
    st.markdown("### ğŸ“¦ å½“å‰åˆ†æäº§å“")
    st.info(f"**{product_name}**\n\näº§å“è¯´æ˜ä¹¦å·²å‘é‡åŒ–å­˜å‚¨")
    
    st.divider()
    
    # API Key è¾“å…¥
    st.markdown("### ğŸ”‘ API é…ç½®")
    
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–
    env_api_key = os.getenv("DASHSCOPE_API_KEY", "")
    default_api_key = env_api_key if env_api_key else ""
    
    # å¦‚æœç¯å¢ƒå˜é‡ä¸­æœ‰ï¼Œæ˜¾ç¤ºæç¤ºï¼›å¦åˆ™å…è®¸ç”¨æˆ·è¾“å…¥
    if env_api_key:
        st.info("âœ… å·²ä»ç¯å¢ƒå˜é‡ `DASHSCOPE_API_KEY` è¯»å– API Key")
        api_key = env_api_key
    else:
        api_key = st.text_input(
            "DashScope API Key (é˜¿é‡Œåƒé—®)",
            type="password",
            value="",
            placeholder="sk-... æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY",
            help="ç”¨äº RAG æ·±åº¦åˆ†æåŠŸèƒ½ã€‚æ¨èæ–¹å¼ï¼šåœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼Œæ·»åŠ  DASHSCOPE_API_KEY=your-key"
        )
        
        if api_key:
            st.success("âœ… API Key å·²é…ç½®ï¼ˆä¸´æ—¶ï¼Œä»…æœ¬æ¬¡ä¼šè¯æœ‰æ•ˆï¼‰")
        else:
            st.warning("âš ï¸ è¯·é…ç½® API Key ä»¥å¯ç”¨ RAG åˆ†æåŠŸèƒ½")
    
    st.divider()
    
    # æ•°æ®æ¦‚è§ˆ
    st.markdown("### ğŸ“Š æ•°æ®æº")
    st.caption(f"ğŸ“„ è¯„è®ºæ•°æ®: `user_reviews.csv`")
    st.caption(f"ğŸ“‹ äº§å“è¯´æ˜: `dji_spec.pdf` (å·²å‘é‡åŒ–)")
    st.caption(f"ğŸ’¾ å‘é‡åº“: `./chroma_db`")
    st.caption(f"ğŸ• æœ€åæ›´æ–°: 2025-01-15")


# ==================== ä¸»ç•Œé¢ ====================
# æ ‡é¢˜åŒº
st.markdown('<h1 class="main-title">ReviewOps</h1>', unsafe_allow_html=True)
st.markdown("**ç”¨æˆ·åé¦ˆå†³ç­–ä¸­å°** Â· è®©äº§å“å†³ç­–æœ‰æ®å¯ä¾")
st.markdown("---")

# ==================== å…¨å±€çŠ¶æ€åˆå§‹åŒ– (SSOT) ====================
# æ£€æŸ¥å¹¶åˆå§‹åŒ– all_reviewsï¼ˆSingle Source of Truthï¼‰
if 'all_reviews' not in st.session_state:
    # åˆå§‹åŒ–ï¼šä» CSV æ–‡ä»¶åŠ è½½å†å²æ•°æ®
    st.session_state.all_reviews = reviews_df.to_dict('records')
    st.session_state.last_run_increment = 0
    # åˆå§‹åŒ–æŒ‡æ ‡åŸºå‡†å€¼ï¼ˆç”¨äºè®¡ç®—å¢é‡ï¼‰
    if len(st.session_state.all_reviews) > 0:
        init_df = pd.DataFrame(st.session_state.all_reviews)
        if 'rating' in init_df.columns:
            init_df['rating'] = pd.to_numeric(init_df['rating'], errors='coerce').fillna(0)
            init_total, init_avg, init_negative = calculate_metrics(init_df)
            st.session_state['prev_total_reviews'] = init_total
            st.session_state['prev_avg_rating'] = init_avg
            st.session_state['prev_negative_ratio'] = init_negative
        else:
            st.session_state['prev_total_reviews'] = 0
            st.session_state['prev_avg_rating'] = 0.0
            st.session_state['prev_negative_ratio'] = 0.0
    else:
        st.session_state['prev_total_reviews'] = 0
        st.session_state['prev_avg_rating'] = 0.0
        st.session_state['prev_negative_ratio'] = 0.0

# åˆå§‹åŒ– RAG åˆ†æç»“æœå­˜å‚¨
if 'latest_rag_results' not in st.session_state:
    st.session_state.latest_rag_results = []

# åˆå§‹åŒ–å¢é‡å·¡æ£€ç›¸å…³çŠ¶æ€
if 'last_run_time' not in st.session_state:
    st.session_state.last_run_time = None
if 'incremental_rag_results' not in st.session_state:
    st.session_state.incremental_rag_results = []  # å­˜å‚¨æœ¬æ¬¡å·¡æ£€çš„RAGç»“æœ

# åˆå§‹åŒ–å†å²å·¡æ£€è®°å½•ï¼ˆå®æ—¶é£é™©åŠ¨æ€æµï¼‰
if 'incident_history' not in st.session_state:
    st.session_state.incident_history = []  # å­˜å‚¨æ‰€æœ‰å†å²å·¡æ£€æ‰¹æ¬¡

# æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°é¡µé¢ä»¥æ›´æ–°æ•°æ®æ¦‚è§ˆ
if st.session_state.get('need_refresh', False):
    st.session_state['need_refresh'] = False
    # å»¶è¿Ÿåˆ·æ–°ï¼Œè®©ç”¨æˆ·æœ‰æ—¶é—´çœ‹æ¸…å·¥ä½œæµå®Œæˆæç¤º
    time.sleep(2)
    st.rerun()

# ==================== é¡¶éƒ¨ Dashboard ====================
# ä½¿ç”¨å®¹å™¨ç»Ÿä¸€æ¨¡å—å¤§å°
with st.container():
    st.markdown("## ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
    
    # è®¡ç®—æŒ‡æ ‡ - åŸºäº session_state.all_reviewsï¼ˆSSOTï¼‰
    all_reviews = st.session_state.get('all_reviews', [])
    
    # ç¡®ä¿ all_reviews æ˜¯åˆ—è¡¨ä¸”ä¸ä¸ºç©º
    if not all_reviews:
        all_reviews_df = pd.DataFrame(columns=['rating'])
    else:
        # åˆ›å»º DataFrameï¼Œç¡®ä¿æ‰€æœ‰è¯„è®ºéƒ½è¢«åŒ…å«
        all_reviews_df = pd.DataFrame(all_reviews)
        
        # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®
        if len(all_reviews_df) > 0:
            # ç¡®ä¿ rating åˆ—å­˜åœ¨ä¸”ä¸ºæ•°å€¼ç±»å‹
            if 'rating' not in all_reviews_df.columns:
                all_reviews_df['rating'] = 0
            else:
                # ç¡®ä¿ rating æ˜¯æ•°å€¼ç±»å‹ï¼Œå¤„ç†å¯èƒ½çš„å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                all_reviews_df['rating'] = pd.to_numeric(all_reviews_df['rating'], errors='coerce').fillna(0)
            
            # å»é‡ï¼šåŸºäº review_id å»é‡ï¼Œé¿å…é‡å¤è®¡ç®—
            if 'review_id' in all_reviews_df.columns:
                all_reviews_df = all_reviews_df.drop_duplicates(subset=['review_id'], keep='last')
    
    # è®¡ç®—æŒ‡æ ‡ï¼ˆå¼ºåˆ¶é‡æ–°è®¡ç®—ï¼Œä¸ä½¿ç”¨ç¼“å­˜ï¼‰
    # é‡è¦ï¼šæ¯æ¬¡é¡µé¢æ¸²æŸ“æ—¶éƒ½é‡æ–°è®¡ç®—ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°æ•°æ®
    total_reviews, avg_rating, negative_ratio = calculate_metrics(all_reviews_df)
    
    # è°ƒè¯•ï¼šæ˜¾ç¤ºå®é™…æ•°æ®çŠ¶æ€ï¼ˆå¸®åŠ©æ’æŸ¥é—®é¢˜ï¼Œå¯ä»¥ä¸´æ—¶å¯ç”¨ï¼‰
    if len(all_reviews_df) > 0 and 'rating' in all_reviews_df.columns:
        rating_series = pd.to_numeric(all_reviews_df['rating'], errors='coerce').dropna()
        if len(rating_series) > 0:
            positive_count = len(rating_series[rating_series >= 4])
            negative_count = len(rating_series[rating_series < 3])
            neutral_count = len(rating_series[(rating_series >= 3) & (rating_series < 4)])
            # ä¸´æ—¶è°ƒè¯•ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦å¯ä»¥å–æ¶ˆæ³¨é‡Šï¼‰
            # with st.expander("ğŸ” æ•°æ®è°ƒè¯•ä¿¡æ¯", expanded=False):
            #     st.write(f"æ€»è¯„è®ºæ•°: {total_reviews}")
            #     st.write(f"æ­£é¢è¯„è®º: {positive_count}, è´Ÿé¢è¯„è®º: {negative_count}, ä¸­æ€§è¯„è®º: {neutral_count}")
            #     st.write(f"å¹³å‡è¯„åˆ†: {avg_rating:.2f}")
            #     st.write(f"è´Ÿé¢å æ¯”: {negative_ratio:.2f}%")
            #     st.write(f"è¯„åˆ†åˆ†å¸ƒ: {rating_series.value_counts().sort_index().to_dict()}")
    
    # è·å–ä¸Šæ¬¡ä¿å­˜çš„å€¼ï¼ˆç”¨äºè®¡ç®—å¢é‡ï¼‰
    prev_total = st.session_state.get('prev_total_reviews', 0)
    prev_avg = st.session_state.get('prev_avg_rating', 0.0)
    prev_negative_ratio = st.session_state.get('prev_negative_ratio', 0.0)
    
    # è®¡ç®— delta å€¼ï¼ˆåªæœ‰å½“æœ‰å†å²æ•°æ®ä¸”æ€»æ•°å˜åŒ–æ—¶æ‰è®¡ç®—ï¼‰
    if prev_total > 0 and prev_total != total_reviews:
        # æ€»æ•°å‘ç”Ÿå˜åŒ–ï¼Œè¯´æ˜æœ‰æ–°æ•°æ®ï¼Œè®¡ç®—å¢é‡
        avg_delta = avg_rating - prev_avg
        negative_delta = negative_ratio - prev_negative_ratio
    elif prev_total == 0:
        # é¦–æ¬¡è¿è¡Œï¼Œæ²¡æœ‰å†å²æ•°æ®
        avg_delta = None
        negative_delta = None
    else:
        # æ€»æ•°æœªå˜åŒ–ï¼Œä½†å¯èƒ½æ•°æ®æœ‰æ›´æ–°ï¼Œä»ç„¶è®¡ç®—å¢é‡
        avg_delta = avg_rating - prev_avg if prev_avg > 0 else None
        negative_delta = negative_ratio - prev_negative_ratio if prev_negative_ratio > 0 else None
    
    # ä¿å­˜å½“å‰å€¼ä½œä¸ºä¸‹æ¬¡çš„åŸºå‡†ï¼ˆæ¯æ¬¡éƒ½è¦æ›´æ–°ï¼Œç¡®ä¿ä¸‹æ¬¡è®¡ç®—æ—¶ä½¿ç”¨æœ€æ–°å€¼ï¼‰
    # é‡è¦ï¼šå¿…é¡»åœ¨æ¯æ¬¡æ¸²æŸ“æ—¶æ›´æ–°ï¼Œç¡®ä¿ä¸‹æ¬¡è®¡ç®—æ—¶ä½¿ç”¨æœ€æ–°å€¼
    st.session_state['prev_total_reviews'] = total_reviews
    st.session_state['prev_avg_rating'] = avg_rating
    st.session_state['prev_negative_ratio'] = negative_ratio
    
    # ä¸‰ä¸ªæŒ‡æ ‡å¡ç‰‡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # åŠ¨æ€æ˜¾ç¤ºå¢é‡ï¼ˆåŸºäº last_run_incrementï¼‰
        delta_text = f"æœ¬æ¬¡æ–°å¢ {st.session_state.last_run_increment} æ¡" if st.session_state.last_run_increment > 0 else None
        st.metric(
            label="ğŸ“ æ€»è¯„è®ºæ•°",
            value=f"{total_reviews}",
            delta=delta_text,
            delta_color="normal"
        )
    
    with col2:
        # æ˜¾ç¤ºå¹³å‡è¯„åˆ†ï¼Œå¸¦å¢é‡å˜åŒ–
        delta_text_avg = f"{avg_delta:+.1f}" if avg_delta is not None and abs(avg_delta) > 0.01 else None
        st.metric(
            label="â­ å¹³å‡è¯„åˆ†",
            value=f"{avg_rating:.1f}",
            delta=delta_text_avg,
            delta_color="normal" if avg_delta is None or avg_delta >= 0 else "inverse"
        )
    
    with col3:
        # æ˜¾ç¤ºè´Ÿé¢è¯„ä»·å æ¯”ï¼Œå¸¦å¢é‡å˜åŒ–
        delta_text_negative = f"{negative_delta:+.1f}%" if negative_delta is not None and abs(negative_delta) > 0.01 else None
        st.metric(
            label="ğŸ˜” è´Ÿé¢è¯„ä»·å æ¯”",
            value=f"{negative_ratio:.1f}%",
            delta=delta_text_negative,
            delta_color="inverse" if negative_delta is None or negative_delta <= 0 else "normal"
        )

# AI æ¯æ—¥ç®€æŠ¥ - ä½¿ç”¨å®¹å™¨ç»Ÿä¸€å¤§å°
with st.container():
    with st.expander("ğŸ¤– **AI æ¯æ—¥ç®€æŠ¥** - ç‚¹å‡»å±•å¼€", expanded=True):
        ai_brief = generate_ai_brief(all_reviews_df, negative_ratio)
        st.markdown(ai_brief)

st.markdown("---")

# ==================== Tab åˆ†é¡µç»“æ„ ====================
# ä½¿ç”¨å®¹å™¨ç»Ÿä¸€æ¨¡å—å¤§å°
with st.container():
    tab_auto, tab_manual = st.tabs(["ğŸ›¡ï¸ æ™ºèƒ½å·¡æ£€æ§åˆ¶å°", "ğŸ”¬ å•æ¡å½’å› å®éªŒå®¤"])

# ==================== Tab 1: æ™ºèƒ½å·¡æ£€æ§åˆ¶å° ====================
with tab_auto:
    st.markdown("### âš¡ æ™ºèƒ½å·¥ä½œæµ")
    st.caption("åŸºäº LangGraph çš„è‡ªåŠ¨åŒ–å·¡æ£€ç³»ç»Ÿï¼Œè‡ªåŠ¨ç›‘æ§ã€ç­›é€‰ã€åˆ†æå’Œç”Ÿæˆè¡ŒåŠ¨å»ºè®®")
    
    # ä¼˜åŒ–æŒ‰é’®å¸ƒå±€ï¼šå·¦ä¾§æŒ‰é’®ï¼Œå³ä¾§ä¿¡æ¯
    col_btn, col_info = st.columns([1, 3])
    with col_btn:
        workflow_button = st.button("âš¡ è¿è¡Œæ™ºèƒ½å·¥ä½œæµ", type="primary", use_container_width=True, key="workflow_btn_auto")
    with col_info:
        # å‚ç›´å±…ä¸­æ˜¾ç¤ºä¸Šæ¬¡å·¡æ£€æ—¶é—´ï¼Œä½¿ç”¨ç°è‰²å°å­—
        last_run_time = st.session_state.get('last_run_time', 'ä»æœª')
        st.markdown(
            f"<div style='padding-top: 10px; color: #6b7280; font-size: 0.9rem;'>ğŸ•’ ä¸Šæ¬¡è‡ªåŠ¨å·¡æ£€ï¼š{last_run_time}</div>",
            unsafe_allow_html=True
        )
    
    # ==================== æ™ºèƒ½å·¥ä½œæµæ‰§è¡Œ ====================
    # Trigger (æŒ‰é’®éƒ¨åˆ†): åªè´Ÿè´£è¿è¡Œ Graphï¼Œå°†ç»“æœè¿½åŠ åˆ° st.session_state.incident_history
    # ä¹‹åç«‹åˆ»è°ƒç”¨ st.rerun()ï¼Œä¸åœ¨è¿™é‡Œå†™ä»»ä½• st.markdown æˆ– UI æ¸²æŸ“ä»£ç ï¼
    if workflow_button:
        # æ£€æŸ¥ API Key
        if not api_key:
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® DashScope API Key")
            st.stop()
        
        try:
            # å¯¼å…¥å·¥ä½œæµ
            from agent_graph import graph_app
            
            # è®°å½•æœ¬æ¬¡å·¡æ£€å¼€å§‹æ—¶é—´
            import datetime
            current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # åˆå§‹åŒ–çŠ¶æ€ï¼ˆå¢é‡å·¡æ£€ï¼šä¿ç•™å·²å¤„ç†çš„IDï¼‰
            initial_state = {
                "raw_reviews": [],
                "critical_reviews": [],
                "rag_analysis_results": [],
                "action_plans": [],
                "logs": [],
                "processed_ids": st.session_state.get('processed_ids', [])  # ä¿ç•™å†å²å·²å¤„ç†ID
            }
            
            # æ¸…ç©ºæœ¬æ¬¡å·¡æ£€çš„ç»“æœï¼ˆåªä¿ç•™å†å²æ•°æ®ï¼‰
            st.session_state.incremental_rag_results = []
            st.session_state.incremental_action_plans = []
            
            # ä½¿ç”¨ st.status å±•ç¤ºå®æ—¶æ—¥å¿—ï¼ˆæ¢å¤è¿è¡Œè¿‡ç¨‹æ˜¾ç¤ºï¼‰
            with st.status("ğŸ”„ å·¥ä½œæµè¿è¡Œä¸­...", expanded=True) as status:
                st.write("ğŸš€ å¯åŠ¨æ™ºèƒ½å·¥ä½œæµ...")
                
                # æ•°æ®åŒæ­¥ï¼šä½¿ç”¨ stream() ç›‘å¬æµå¼è¾“å‡º
                final_state = initial_state.copy()
                for event in graph_app.stream(initial_state):
                    # éå†æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º
                    for node_name, node_output in event.items():
                        # åˆå¹¶çŠ¶æ€
                        if isinstance(node_output, dict):
                            final_state.update(node_output)
                        
                        # æ£€æµ‹ node_monitor äº§å‡ºçš„ raw_reviews
                        if node_name == "monitor" and isinstance(node_output, dict) and "raw_reviews" in node_output:
                            new_reviews = node_output.get("raw_reviews", [])
                            if new_reviews:
                                # æ•°æ®åŒæ­¥ï¼šç«‹å³è¿½åŠ åˆ° session_state.all_reviewsï¼ˆå¢é‡ç´¯åŠ ï¼‰
                                st.session_state.all_reviews.extend(new_reviews)
                                st.session_state.last_run_increment = len(new_reviews)
                                st.write(f"ğŸ“¥ æ•°æ®åŒæ­¥ï¼šå·²æ·»åŠ  {len(new_reviews)} æ¡æ–°è¯„è®ºåˆ°å…¨å±€çŠ¶æ€ï¼ˆç´¯è®¡ï¼š{len(st.session_state.all_reviews)} æ¡ï¼‰")
                        
                        # æ£€æµ‹ node_rag_analysis äº§å‡ºçš„ rag_analysis_resultsï¼ˆæœ¬æ¬¡å·¡æ£€çš„æ–°å¢ç»“æœï¼‰
                        if node_name == "rag_analysis" and isinstance(node_output, dict) and "rag_analysis_results" in node_output:
                            rag_results = node_output.get("rag_analysis_results", [])
                            if rag_results:
                                # ä¿å­˜æœ¬æ¬¡å·¡æ£€çš„RAGç»“æœï¼ˆå¢é‡ï¼‰
                                st.session_state.incremental_rag_results.extend(rag_results)
                                # åŒæ—¶æ›´æ–°å…¨å±€æœ€æ–°ç»“æœï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
                                st.session_state.latest_rag_results = rag_results
                                st.write(f"ğŸ“„ æœ¬æ¬¡å·¡æ£€å‘ç° {len(rag_results)} æ¡RAGå½’å› ç»“æœï¼ˆç´¯è®¡ï¼š{len(st.session_state.incremental_rag_results)} æ¡ï¼‰")
                        
                        # æ£€æµ‹ node_action_gen äº§å‡ºçš„ action_plansï¼ˆæœ¬æ¬¡å·¡æ£€çš„æ–°å¢ç»“æœï¼‰
                        if node_name == "action_gen" and isinstance(node_output, dict) and "action_plans" in node_output:
                            action_plans = node_output.get("action_plans", [])
                            if action_plans:
                                # ä¿å­˜æœ¬æ¬¡å·¡æ£€çš„è¡ŒåŠ¨å»ºè®®ï¼ˆå¢é‡ï¼‰
                                st.session_state.incremental_action_plans = action_plans
                                st.write(f"ğŸ’¡ æœ¬æ¬¡å·¡æ£€ç”Ÿæˆ {len(action_plans)} æ¡è¡ŒåŠ¨å»ºè®®")
                        
                        # æ›´æ–°å·²å¤„ç†çš„IDé›†åˆï¼ˆç”¨äºå¹‚ç­‰æ€§ï¼‰
                        if isinstance(node_output, dict) and "processed_ids" in node_output:
                            processed_ids = node_output.get("processed_ids", [])
                            if processed_ids:
                                existing_ids = set(st.session_state.get('processed_ids', []))
                                new_ids = set(processed_ids)
                                st.session_state['processed_ids'] = list(existing_ids | new_ids)
                        
                        # å®æ—¶æ˜¾ç¤ºæ—¥å¿—
                        if isinstance(node_output, dict) and "logs" in node_output:
                            logs = node_output.get("logs", [])
                            for log in logs:
                                st.write(log)
                                time.sleep(0.2)  # æ¨¡æ‹Ÿå®æ—¶æ›´æ–°
                
                status.update(label="âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ", state="complete")
                st.write("â³ æ­£åœ¨åˆ·æ–°é¡µé¢ä»¥æ›´æ–°ç»Ÿè®¡æ•°æ®...")
                time.sleep(1)
            
            # æ›´æ–°ä¸Šæ¬¡å·¡æ£€æ—¶é—´
            st.session_state.last_run_time = current_time
            
            # ==================== æ•°æ®å¤„ç†ï¼šä¿å­˜åˆ°å†å²è®°å½• ====================
            result = final_state
            rag_results = result.get("rag_analysis_results", [])
            action_plans = result.get("action_plans", [])
            
            # ç”Ÿæˆæ‰¹æ¬¡è®°å½•ï¼Œæ’å…¥åˆ°å†å²è®°å½•å¤´éƒ¨ï¼ˆæœ€æ–°çš„åœ¨æœ€ä¸Šé¢ï¼‰
            batch_record = {
                'time': current_time,
                'rag_results': rag_results,
                'actions': action_plans,
                'new_reviews_count': len(final_state.get("raw_reviews", [])),
                'critical_count': len(result.get("critical_reviews", []))
            }
            
            # æ’å…¥åˆ°å¤´éƒ¨ï¼ˆPrependï¼‰
            st.session_state.incident_history.insert(0, batch_record)
            
            # å­˜å‚¨ç»“æœåˆ° session_stateï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
            st.session_state['workflow_result'] = result
            st.session_state['workflow_completed'] = True
            st.session_state['need_refresh'] = True
            
            # å¼ºåˆ¶æ¸…é™¤ä¹‹å‰çš„æŒ‡æ ‡ç¼“å­˜ï¼Œç¡®ä¿ä¸‹æ¬¡è®¡ç®—æ—¶ä½¿ç”¨æœ€æ–°æ•°æ®
            # æ³¨æ„ï¼šä¸æ¸…é™¤ prev_* å€¼ï¼Œå› ä¸ºéœ€è¦ç”¨äºè®¡ç®— delta
            # ä½†ç¡®ä¿ all_reviews å·²ç»æ›´æ–°
            
            # ç«‹å³è°ƒç”¨ st.rerun() è§¦å‘é¡µé¢åˆ·æ–°ï¼Œè®©æ¸²æŸ“åŒºåŸŸæ˜¾ç¤ºæ–°æ•°æ®
            st.rerun()
            
        except ImportError as e:
            st.error(f"âŒ æ— æ³•å¯¼å…¥å·¥ä½œæµæ¨¡å—: {e}")
            st.info("ğŸ’¡ è¯·ç¡®ä¿ `agent_graph.py` æ–‡ä»¶å­˜åœ¨ä¸”å·²æ­£ç¡®é…ç½®")
        except Exception as e:
            st.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            st.exception(e)
    
    # ==================== æŒä¹…åŒ–æ¸²æŸ“åŒºåŸŸï¼šå®æ—¶é£é™©åŠ¨æ€æµ ====================
    incident_history = st.session_state.get('incident_history', [])
    
    if incident_history:
        st.markdown("---")
        
        # ==================== Part A: æœ€æ–°åŠ¨æ€ (Hero Section) ====================
        latest_batch = incident_history[0]
        latest_rag_results = latest_batch.get('rag_results', [])
        latest_actions = latest_batch.get('actions', [])
        latest_time = latest_batch.get('time', 'æœªçŸ¥æ—¶é—´')
        latest_new_reviews = latest_batch.get('new_reviews_count', 0)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ P0 çº§é£é™©ï¼ˆHigh ä¼˜å…ˆçº§çš„ Action æˆ–äº§å“ç¼ºé™·çš„ RAGï¼‰
        has_p0_risk = False
        if latest_actions:
            has_p0_risk = any(action.get('priority') == 'High' for action in latest_actions)
        if not has_p0_risk and latest_rag_results:
            has_p0_risk = any('äº§å“ç¼ºé™·' in rag.get('conclusion', '') for rag in latest_rag_results)
        
        # æ˜¾ç¤ºæ ‡é¢˜å’Œç»Ÿè®¡
        col_title, col_stats = st.columns([2, 1])
        with col_title:
            st.markdown("### ğŸš¨ æœ¬æ¬¡å·¡æ£€å‘ç° (Latest)")
        with col_stats:
            st.caption(f"ğŸ“… {latest_time} Â· æ–°å¢ {latest_new_reviews} æ¡è¯„è®º")
        
        # å¦‚æœæœ‰ P0 çº§é£é™©ï¼Œä½¿ç”¨ st.error å®¹å™¨åŒ…è£¹å¢å¼ºè­¦ç¤ºæ„Ÿ
        if has_p0_risk:
            st.error("âš ï¸ **æ£€æµ‹åˆ°é«˜é£é™©é—®é¢˜ï¼Œè¯·ç«‹å³å¤„ç†ï¼**")
        
        # Case-Based æˆç»„æ¸²æŸ“ï¼šé€šè¿‡ review_id åŒ¹é… RAG å’Œ Action
        if latest_rag_results:
            # åˆ›å»º action å­—å…¸ï¼Œä»¥ review_id ä¸º keyï¼Œæ–¹ä¾¿æŸ¥æ‰¾
            # æ”¯æŒå®Œæ•´åŒ¹é…å’Œéƒ¨åˆ†åŒ¹é…ï¼ˆå¤„ç†å¯èƒ½çš„ ID æ ¼å¼å·®å¼‚ï¼‰
            action_dict = {}
            for action in latest_actions:
                review_id = action.get('review_id')
                if review_id:
                    action_dict[review_id] = action
                    # ä¹Ÿæ”¯æŒ base_id åŒ¹é…ï¼ˆå¦‚æœ review_id åŒ…å«ä¸‹åˆ’çº¿ï¼‰
                    if '_' in str(review_id):
                        base_id = str(review_id).split('_')[0]
                        if base_id not in action_dict:
                            action_dict[base_id] = action
            
            for item_idx, rag_result in enumerate(latest_rag_results):
                # é€šè¿‡ review_id åŒ¹é…å¯¹åº”çš„ Action
                review_id = rag_result.get("review_id")
                action_item = None
                
                if review_id:
                    # ä¼˜å…ˆå®Œæ•´åŒ¹é…
                    action_item = action_dict.get(review_id)
                    # å¦‚æœå®Œæ•´åŒ¹é…å¤±è´¥ï¼Œå°è¯• base_id åŒ¹é…
                    if not action_item and '_' in str(review_id):
                        base_id = str(review_id).split('_')[0]
                        action_item = action_dict.get(base_id)
                
                # å¦‚æœè¿˜æ˜¯æ²¡åŒ¹é…åˆ°ï¼Œå°è¯•æŒ‰ç´¢å¼•åŒ¹é…ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
                if not action_item and item_idx < len(latest_actions):
                    action_item = latest_actions[item_idx]
                
                # æ¸²æŸ“å®Œæ•´çš„ Caseï¼ˆRAG + Action æˆå¯¹ï¼‰
                render_case_group(rag_result, action_item, batch_idx=0, item_idx=item_idx)
                # Case ä¹‹é—´çš„åˆ†éš”
                if item_idx < len(latest_rag_results) - 1:
                    st.markdown("")  # ç©ºç™½é—´éš”ï¼Œé¿å…æ–‡å­—ç²˜è¿
        
        # ==================== Part B: å†å²å›æº¯ (Scrollable Container) ====================
        history_batches = incident_history[1:] if len(incident_history) > 1 else []
        
        if history_batches:
            st.divider()  # åˆ†å‰²çº¿ï¼Œæ¸…æ™°åŒºåˆ†æœ€æ–°å’Œå†å²
            st.markdown("#### ğŸ“œ å†å²å·¡æ£€è®°å½•")
            
            # ä½¿ç”¨å›ºå®šé«˜åº¦çš„æ»šåŠ¨å®¹å™¨
            with st.container(height=500, border=False):
                for batch_idx, batch in enumerate(history_batches, start=1):
                    batch_time = batch.get('time', 'æœªçŸ¥æ—¶é—´')
                    rag_results = batch.get('rag_results', [])
                    actions = batch.get('actions', [])
                    new_reviews_count = batch.get('new_reviews_count', 0)
                    
                    # ä½¿ç”¨ expander æŠ˜å å†å²æ‰¹æ¬¡
                    with st.expander(f"ğŸ“… å·¡æ£€æ‰¹æ¬¡: {batch_time} (æ–°å¢ {new_reviews_count} æ¡è¯„è®º)", expanded=False):
                        # Case-Based æˆç»„æ¸²æŸ“ï¼šé€šè¿‡ review_id åŒ¹é… RAG å’Œ Action
                        if rag_results:
                            # åˆ›å»º action å­—å…¸ï¼Œä»¥ review_id ä¸º keyï¼Œæ–¹ä¾¿æŸ¥æ‰¾
                            # æ”¯æŒå®Œæ•´åŒ¹é…å’Œéƒ¨åˆ†åŒ¹é…ï¼ˆå¤„ç†å¯èƒ½çš„ ID æ ¼å¼å·®å¼‚ï¼‰
                            action_dict = {}
                            for action in actions:
                                review_id = action.get('review_id')
                                if review_id:
                                    action_dict[review_id] = action
                                    # ä¹Ÿæ”¯æŒ base_id åŒ¹é…ï¼ˆå¦‚æœ review_id åŒ…å«ä¸‹åˆ’çº¿ï¼‰
                                    if '_' in str(review_id):
                                        base_id = str(review_id).split('_')[0]
                                        if base_id not in action_dict:
                                            action_dict[base_id] = action
                            
                            for item_idx, rag_result in enumerate(rag_results):
                                # é€šè¿‡ review_id åŒ¹é…å¯¹åº”çš„ Action
                                review_id = rag_result.get("review_id")
                                action_item = None
                                
                                if review_id:
                                    # ä¼˜å…ˆå®Œæ•´åŒ¹é…
                                    action_item = action_dict.get(review_id)
                                    # å¦‚æœå®Œæ•´åŒ¹é…å¤±è´¥ï¼Œå°è¯• base_id åŒ¹é…
                                    if not action_item and '_' in str(review_id):
                                        base_id = str(review_id).split('_')[0]
                                        action_item = action_dict.get(base_id)
                                
                                # å¦‚æœè¿˜æ˜¯æ²¡åŒ¹é…åˆ°ï¼Œå°è¯•æŒ‰ç´¢å¼•åŒ¹é…ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
                                if not action_item and item_idx < len(actions):
                                    action_item = actions[item_idx]
                                
                                # æ¸²æŸ“å®Œæ•´çš„ Caseï¼ˆRAG + Action æˆå¯¹ï¼‰
                                render_case_group(rag_result, action_item, batch_idx=batch_idx, item_idx=item_idx)
                                # Case ä¹‹é—´çš„åˆ†éš”
                                if item_idx < len(rag_results) - 1:
                                    st.markdown("")  # ç©ºç™½é—´éš”ï¼Œé¿å…æ–‡å­—ç²˜è¿
                        
                        # æ‰¹æ¬¡ä¹‹é—´çš„åˆ†éš”
                        if batch_idx < len(history_batches):
                            st.markdown("")
    else:
        # å¦‚æœå·¥ä½œæµæœªè¿è¡Œï¼Œæ˜¾ç¤ºæç¤º
        st.info("ğŸ‘† ç‚¹å‡»ä¸Šæ–¹ã€Œè¿è¡Œæ™ºèƒ½å·¥ä½œæµã€æŒ‰é’®ï¼Œå¼€å§‹é¦–æ¬¡å¢é‡å·¡æ£€")

# ==================== Tab 2: å•æ¡å½’å› å®éªŒå®¤ ====================
with tab_manual:
    st.markdown("### ğŸ”¬ å•æ¡è¯„è®ºå½’å› åˆ†æ")
    st.caption("è¾“å…¥å•æ¡ç”¨æˆ·è¯„è®ºï¼Œè¿›è¡Œæ·±åº¦ RAG å½’å› åˆ†æ")
    
    # å•æ¡è¯„è®ºè¾“å…¥
    user_input = st.text_area(
        "ğŸ“ è¯·è¾“å…¥ç”¨æˆ·è¯„è®º",
        placeholder="ä¾‹å¦‚ï¼šå¤œé—´é£è¡Œæ—¶é¿éšœåŠŸèƒ½å®Œå…¨å¤±æ•ˆï¼Œå·®ç‚¹æ’å¢™...",
        height=100,
        key="manual_review_input"
    )
    
    analyze_button = st.button("ğŸš€ å¼€å§‹å½’å› åˆ†æ", use_container_width=True, key="analyze_btn_manual")
    
    if analyze_button:
        # æ£€æŸ¥è¾“å…¥
        if not user_input or not user_input.strip():
            st.warning("âš ï¸ è¯·è¾“å…¥ç”¨æˆ·è¯„è®º")
            st.stop()
        
        # æ£€æŸ¥ API Key
        if not api_key:
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® DashScope API Key")
            st.stop()
        
        # åˆå§‹åŒ– RAG ç»„ä»¶
        with st.spinner("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– RAG ç³»ç»Ÿ..."):
            vectorstore = init_vectorstore(api_key)
            llm = init_llm(api_key)
            
            if not vectorstore or not llm:
                st.error("âŒ RAG ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key å’Œå‘é‡åº“")
                st.stop()
        
        # æ‰§è¡Œ RAG åˆ†æ
        with st.spinner("ğŸ§  AI æ­£åœ¨åˆ†æä¸­..."):
            spec_match, conclusion, source_docs = match_with_spec(
                user_input,
                qa_chain={'vectorstore': vectorstore, 'llm': llm}
            )
        
        st.success("âœ… åˆ†æå®Œæˆï¼")
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        
        col_left, col_right = st.columns([1, 1])
        
        with col_left:
            st.markdown("##### ğŸ’¬ ç”¨æˆ·è¯„è®º")
            st.info(user_input)
            
            st.markdown("##### ğŸ¤– AI åˆ¤å®šç»“è®º")
            if "âœ…" in conclusion:
                st.success(conclusion)
            elif "âš ï¸" in conclusion:
                st.warning(conclusion)
            elif "â“" in conclusion:
                st.info(conclusion)
            else:
                st.info(conclusion)
        
        with col_right:
            st.markdown("##### ğŸ“– è¯´æ˜ä¹¦å¯¹åº”å‚æ•°")
            if len(spec_match) > 500:
                with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯´æ˜ä¹¦å†…å®¹", expanded=True):
                    st.markdown(spec_match)
            else:
                st.markdown(f"<div style='background-color: #f0f9ff; padding: 1rem; border-radius: 8px; border-left: 4px solid #0ea5e9;'>{spec_match}</div>", unsafe_allow_html=True)
            
            # æ˜¾ç¤ºè¯æ®æ¥æº
            if source_docs:
                st.markdown("")
                with st.expander(f"ğŸ“š æ£€ç´¢åˆ°çš„è¯æ®æ¥æº ({len(source_docs)} æ¡)", expanded=False):
                    for i, doc in enumerate(source_docs, 1):
                        st.markdown(f"**è¯æ® {i}:**")
                        st.text_area(
                            label="",
                            value=doc,
                            height=150,
                            key=f"manual_source_doc_{i}",
                            disabled=True,
                            label_visibility="collapsed"
                        )
                        if i < len(source_docs):
                            st.markdown("---")
        
        # ç”Ÿæˆå•æ¡è¯„è®ºçš„ Action Plan
        st.markdown("---")
        st.markdown("### ğŸ’¡ è¡ŒåŠ¨å»ºè®®")
        
        action_plan = generate_action_plan(
            topic_name="å•æ¡è¯„è®ºåˆ†æ",
            rag_conclusion=conclusion,
            user_complaints=[user_input],
            llm=llm
        )
        
        if action_plan:
            action_type = action_plan.get('action_type', 'Doc Update')
            title = action_plan.get('title', '')
            content = action_plan.get('content', '')
            priority = action_plan.get('priority', 'Medium')
            
            # ä¼˜å…ˆçº§é¢œè‰²
            priority_colors = {
                "High": "ğŸ”´",
                "Medium": "ğŸŸ¡",
                "Low": "ğŸŸ¢"
            }
            priority_icon = priority_colors.get(priority, "ğŸŸ¡")
            
            # è¡ŒåŠ¨ç±»å‹å›¾æ ‡
            type_icons = {
                "Jira Ticket": "ğŸ",
                "Doc Update": "ğŸ“",
                "Email Draft": "ğŸ“§",
                "Meeting": "ğŸ“…"
            }
            type_icon = type_icons.get(action_type, "ğŸ“‹")
            
            with st.expander(f"{type_icon} **{title}** Â· {priority_icon} {priority} Â· {action_type}", expanded=True):
                st.markdown(f"**ä¼˜å…ˆçº§ï¼š** {priority}")
                st.markdown(f"**ç±»å‹ï¼š** {action_type}")
                st.markdown(f"**å†…å®¹ï¼š**")
                if len(content) > 500:
                    st.text_area("", value=content, height=150, disabled=True, key="manual_action_content", label_visibility="collapsed")
                else:
                    st.markdown(content)
                
                # Mock æŒ‰é’®
                if action_type == "Jira Ticket":
                    if st.button("ğŸš€ æ¨é€è‡³ Jira", key="manual_jira", use_container_width=True):
                        import random
                        ticket_id = f"DJI-2025-{random.randint(800, 999)}"
                        st.toast(f"âœ… å·¥å•å·²åˆ›å»ºï¼Ticket ID: {ticket_id}", icon="ğŸ‰")
                elif action_type == "Doc Update":
                    if st.button("ğŸ“ åˆ›å»º Notion Task", key="manual_notion", use_container_width=True):
                        st.toast("âœ… Notion ä»»åŠ¡å·²åˆ›å»ºï¼", icon="ğŸ‰")
                elif action_type == "Email Draft":
                    if st.button("ğŸ“§ å¤åˆ¶é‚®ä»¶", key="manual_email", use_container_width=True):
                        st.toast("âœ… é‚®ä»¶å†…å®¹å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼", icon="ğŸ‰")
                elif action_type == "Meeting":
                    if st.button("ğŸ“… åˆ›å»ºä¼šè®®", key="manual_meeting", use_container_width=True):
                        st.toast("âœ… ä¼šè®®å·²åˆ›å»ºï¼", icon="ğŸ‰")
    else:
        st.info("ğŸ‘† è¯·è¾“å…¥ç”¨æˆ·è¯„è®ºå¹¶ç‚¹å‡»ã€Œå¼€å§‹å½’å› åˆ†æã€æŒ‰é’®")

# ===== ä¿ç•™åŸæœ‰çš„æ‰¹é‡åˆ†æåŠŸèƒ½ï¼ˆç”¨äºå…¼å®¹æ€§ï¼Œä½†ä¸åœ¨ Tab ä¸­æ˜¾ç¤ºï¼‰ =====
# æ³¨æ„ï¼šè¿™éƒ¨åˆ†ä»£ç ä¿ç•™åœ¨å…¨å±€ï¼Œä½†ä¸ä¼šåœ¨ UI ä¸­æ˜¾ç¤ºï¼Œä»…ç”¨äºå†…éƒ¨çŠ¶æ€ç®¡ç†
# å·²ç¦ç”¨çš„ä»£ç å—ï¼ˆå·²ç§»åˆ° Tab ä¸­ï¼‰
# æ³¨æ„ï¼šæ‰¹é‡åˆ†æåŠŸèƒ½å·²ç§»é™¤ï¼Œç°åœ¨åªåœ¨ Tab ä¸­æä¾›å•æ¡è¯„è®ºåˆ†æåŠŸèƒ½

# ==================== æ¸…ç†ï¼šåˆ é™¤å…¨å±€é‡å¤çš„ Action åŒº ====================
# æ³¨æ„ï¼šAction å»ºè®®ç°åœ¨åªåœ¨å„è‡ªçš„ Tab ä¸­æ˜¾ç¤ºï¼Œä¸å†åœ¨å…¨å±€æ˜¾ç¤º

# ==================== é¡µè„š ====================
st.markdown("---")
st.markdown(
    """
    <div style="text-align: center; color: #6b7280; font-size: 0.85rem;">
        <p>ğŸ”¬ ReviewOps v1.0 Â· ç”¨æˆ·åé¦ˆå†³ç­–ä¸­å°</p>
        <p>Powered by RAG + LLM Â· Built with Streamlit</p>
    </div>
    """,
    unsafe_allow_html=True
)

