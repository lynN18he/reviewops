"""
ReviewOps Agentic Workflow - åŸºäº LangGraph çš„è‡ªåŠ¨åŒ–å·¡æ£€ç³»ç»Ÿ
"""

import os
import time
import random
from typing import TypedDict, List, Literal
from operator import add
from dotenv import load_dotenv

from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.chat_models import ChatTongyi
import json

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ==================== Mock æ•°æ®æ±  ====================
MOCK_DATA_POOL = [
    {
        "base_id": 101,
        "user_id": "user_001",
        "review_text": "å¤œé—´é£è¡Œæ—¶é¿éšœåŠŸèƒ½å®Œå…¨å¤±æ•ˆï¼Œå·®ç‚¹æ’å¢™ï¼Œè¯´æ˜ä¹¦ä¸Šä¹Ÿæ²¡æ˜ç¡®è¯´æ˜å¤œé—´ä¸æ”¯æŒé¿éšœã€‚",
        "rating": 1
    },
    {
        "base_id": 102,
        "user_id": "user_002",
        "review_text": "äº‘å°æŠ–åŠ¨ä¸¥é‡ï¼Œç”»é¢ä¸ç¨³å®šï¼Œé‡å¯åé—®é¢˜ä¾ç„¶å­˜åœ¨ï¼Œæ€€ç–‘æ˜¯ç¡¬ä»¶è´¨é‡é—®é¢˜ã€‚",
        "rating": 2
    },
    {
        "base_id": 103,
        "user_id": "user_003",
        "review_text": "å¿«é€’åŒ…è£…ç ´æŸï¼Œç­‰äº†å¾ˆä¹…æ‰æ”¶åˆ°ï¼Œç‰©æµä½“éªŒå¾ˆå·®ã€‚",
        "rating": 2
    },
    {
        "base_id": 104,
        "user_id": "user_004",
        "review_text": "æ ‡ç§°ç»­èˆª45åˆ†é’Ÿï¼Œå®é™…åªèƒ½é£20å¤šåˆ†é’Ÿï¼Œç»­èˆªä¸¥é‡è™šæ ‡ï¼Œæ„Ÿè§‰è¢«æ¬ºéª—äº†ã€‚",
        "rating": 1
    },
    {
        "base_id": 105,
        "user_id": "user_005",
        "review_text": "æ•´ä½“ä½“éªŒè¿˜ä¸é”™ï¼Œå°±æ˜¯ç»­èˆªç¨å¾®çŸ­äº†ç‚¹ï¼Œå…¶ä»–åŠŸèƒ½éƒ½æ­£å¸¸ã€‚",
        "rating": 4
    }
]


# ==================== çŠ¶æ€å®šä¹‰ ====================
class ReviewState(TypedDict):
    """å·¥ä½œæµçŠ¶æ€"""
    raw_reviews: List[dict]  # æ–°è¯„è®º
    critical_reviews: List[dict]  # ç­›é€‰åçš„é«˜å±è¯„è®º
    rag_analysis_results: List[dict]  # å½’å› ç»“æœ
    action_plans: List[dict]  # è¡ŒåŠ¨å»ºè®®
    logs: List[str]  # æ—¥å¿—ï¼ˆä½¿ç”¨ operator.add è¿½åŠ ï¼‰


# ==================== çŠ¶æ€ Reducer ====================
# å®šä¹‰çŠ¶æ€åˆå¹¶è§„åˆ™
def reducer(state: ReviewState, update: ReviewState) -> ReviewState:
    """åˆå¹¶çŠ¶æ€æ›´æ–°"""
    # å¯¹äºåˆ—è¡¨ç±»å‹ï¼Œä½¿ç”¨ operator.add è¿½åŠ 
    # å¯¹äºå…¶ä»–ç±»å‹ï¼Œç›´æ¥è¦†ç›–
    merged = state.copy()
    
    # åˆå¹¶åˆ—è¡¨ï¼ˆè¿½åŠ ï¼‰
    if "logs" in update:
        merged["logs"] = state.get("logs", []) + update.get("logs", [])
    if "raw_reviews" in update:
        merged["raw_reviews"] = update.get("raw_reviews", [])
    if "critical_reviews" in update:
        merged["critical_reviews"] = update.get("critical_reviews", [])
    if "rag_analysis_results" in update:
        merged["rag_analysis_results"] = update.get("rag_analysis_results", [])
    if "action_plans" in update:
        merged["action_plans"] = update.get("action_plans", [])
    
    return merged


# ==================== åˆå§‹åŒ– LLM ====================
def init_llm():
    """åˆå§‹åŒ– LLM"""
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    return ChatTongyi(
        model="qwen-plus",
        temperature=0,
        dashscope_api_key=api_key
    )


# ==================== èŠ‚ç‚¹å®šä¹‰ ====================

def node_monitor(state: ReviewState) -> ReviewState:
    """
    èŠ‚ç‚¹ 1: ç›‘æ§æ–°è¯„è®º
    åŠ¨æ€æ¨¡æ‹Ÿç”Ÿæˆå™¨ï¼šä» MOCK_DATA_POOL éšæœºé‡‡æ ·ï¼Œå¹¶æ·»åŠ æ—¶é—´æˆ³åç¼€ç¡®ä¿å”¯ä¸€æ€§
    """
    # åŠ¨æ€é‡‡æ ·ï¼šéšæœºé€‰å– 1-2 æ¡è¯„è®º
    sample_size = random.randint(1, 2)
    sampled_templates = random.sample(MOCK_DATA_POOL, min(sample_size, len(MOCK_DATA_POOL)))
    
    # ä¸ºæ¯æ¡è¯„è®ºæ·»åŠ æ—¶é—´æˆ³åç¼€ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½è¢«è§†ä¸º"æ–°æ•°æ®"
    current_timestamp = int(time.time())
    new_reviews = []
    
    for template in sampled_templates:
        review = {
            "review_id": f"{template['base_id']}_{current_timestamp}",
            "user_id": template['user_id'],
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
            "review_text": template['review_text'],
            "rating": template['rating']
        }
        new_reviews.append(review)
    
    log_message = f"ğŸ“¥ ç›‘æ§èŠ‚ç‚¹ï¼šæ£€æµ‹åˆ° {len(new_reviews)} æ¡æ–°è¯„è®º (ID: {[r['review_id'] for r in new_reviews]})"
    
    return {
        "raw_reviews": new_reviews,
        "logs": [log_message]
    }


def node_filter(state: ReviewState) -> ReviewState:
    """
    èŠ‚ç‚¹ 2: ç­›é€‰é«˜å±è¯„è®º
    ä½¿ç”¨ LLM åˆ¤æ–­æ˜¯å¦åŒ…å«"æ•…éšœ/å®‰å…¨/è´¨é‡"å…³é”®è¯
    """
    llm = init_llm()
    raw_reviews = state.get("raw_reviews", [])
    
    if not raw_reviews:
        log_message = "âš ï¸ ç­›é€‰èŠ‚ç‚¹ï¼šæ— æ–°è¯„è®ºéœ€è¦ç­›é€‰"
        return {
            "critical_reviews": [],
            "logs": [log_message]
        }
    
    # æ„å»ºç­›é€‰ promptï¼ŒåŒ…å«å®Œæ•´çš„ review_id
    reviews_text = "\n".join([
        f"è¯„è®ºID {review['review_id']}: {review['review_text']} (è¯„åˆ†: {review['rating']})"
        for i, review in enumerate(raw_reviews)
    ])
    
    # æå–æ‰€æœ‰ review_id ä¾›å‚è€ƒ
    all_review_ids = [review['review_id'] for review in raw_reviews]
    
    filter_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¯„è®ºï¼Œç­›é€‰å‡ºåŒ…å«"æ•…éšœ/å®‰å…¨/è´¨é‡é—®é¢˜"çš„é«˜å±è¯„è®ºã€‚

è¯„è®ºåˆ—è¡¨ï¼š
{reviews_text}

ç­›é€‰æ ‡å‡†ï¼ˆæ»¡è¶³ä»»ä¸€æ¡ä»¶å³è§†ä¸ºé«˜å±ï¼‰ï¼š
1. è¯„åˆ†ä½äº3æ˜Ÿï¼ˆrating < 3ï¼‰
2. åŒ…å«æ•…éšœã€å¤±æ•ˆã€å®‰å…¨é—®é¢˜ã€è´¨é‡é—®é¢˜ç­‰å…³é”®è¯
3. æ¶‰åŠäº§å“ç¼ºé™·æˆ–å®‰å…¨éšæ‚£ï¼ˆå¦‚ï¼šé¿éšœå¤±æ•ˆã€äº‘å°æŠ–åŠ¨ã€åŠŸèƒ½ä¸å·¥ä½œç­‰ï¼‰

è¯·è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«ï¼š
{{
  "critical_review_ids": [è¯„è®ºIDåˆ—è¡¨ï¼Œå¿…é¡»ä½¿ç”¨å®Œæ•´çš„review_idï¼Œä¾‹å¦‚: {all_review_ids[:2] if len(all_review_ids) >= 2 else all_review_ids}],
  "reason": "ç­›é€‰åŸå› "
}}

é‡è¦ï¼š
- å¿…é¡»ä½¿ç”¨å®Œæ•´çš„ review_idï¼ˆåŒ…å«æ—¶é—´æˆ³éƒ¨åˆ†ï¼‰
- è¯·ç¡®ä¿åŒ…å«æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„é«˜å±è¯„è®ºID
- åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜"""
    
    try:
        response = llm.invoke([HumanMessage(content=filter_prompt)])
        answer = response.content if hasattr(response, 'content') else str(response)
        
        # è§£æ JSON
        json_str = answer.strip()
        if json_str.startswith("```json"):
            json_str = json_str[7:]
        elif json_str.startswith("```"):
            json_str = json_str[3:]
        if json_str.endswith("```"):
            json_str = json_str[:-3]
        json_str = json_str.strip()
        
        result = json.loads(json_str)
        critical_ids = result.get("critical_review_ids", [])
        
        # ç­›é€‰å‡ºé«˜å±è¯„è®ºï¼ˆæ”¯æŒå®Œæ•´IDæˆ–base_idåŒ¹é…ï¼‰
        critical_reviews = []
        for review in raw_reviews:
            review_id = review.get("review_id", "")
            # å°è¯•å®Œæ•´IDåŒ¹é…
            if review_id in critical_ids:
                critical_reviews.append(review)
            else:
                # å°è¯•base_idåŒ¹é…ï¼ˆå¦‚æœLLMè¿”å›çš„æ˜¯æ•°å­—IDï¼‰
                base_id = review_id.split("_")[0] if "_" in review_id else review_id
                if str(base_id) in [str(cid) for cid in critical_ids] or base_id in [str(cid) for cid in critical_ids]:
                    critical_reviews.append(review)
        
        log_message = f"ğŸ” ç­›é€‰èŠ‚ç‚¹ï¼šä» {len(raw_reviews)} æ¡è¯„è®ºä¸­ç­›é€‰å‡º {len(critical_reviews)} æ¡é«˜å±è¯„è®º"
        if critical_reviews:
            log_message += f" (ID: {[r.get('review_id') for r in critical_reviews]})"
        elif critical_ids:
            log_message += f" | LLMè¿”å›çš„ID: {critical_ids}ï¼Œä½†åŒ¹é…å¤±è´¥"
        
        return {
            "critical_reviews": critical_reviews,
            "logs": [log_message]
        }
        
    except Exception as e:
        # å¦‚æœ LLM ç­›é€‰å¤±è´¥ï¼Œä½¿ç”¨é™çº§è§„åˆ™ï¼šrating < 3 æˆ–åŒ…å«å…³é”®è¯
        keywords = ["æ•…éšœ", "å¤±æ•ˆ", "é—®é¢˜", "å", "ä¸å·¥ä½œ", "å®‰å…¨", "å±é™©", "è´¨é‡", "é¿éšœ", "æŠ–åŠ¨", "ä¸ç¨³å®š", "æ’", "å·®ç‚¹", "è™šæ ‡", "æ¬ºéª—"]
        critical_reviews = []
        
        for review in raw_reviews:
            rating = review.get("rating", 5)
            review_text = review.get("review_text", "")
            
            # è¯„åˆ†ä½äº3æ˜Ÿï¼Œæˆ–è€…åŒ…å«å…³é”®è¯
            if rating < 3 or any(keyword in review_text for keyword in keywords):
                critical_reviews.append(review)
        
        log_message = f"ğŸ” ç­›é€‰èŠ‚ç‚¹ï¼ˆé™çº§æ¨¡å¼ï¼‰ï¼šç­›é€‰å‡º {len(critical_reviews)} æ¡é«˜å±è¯„è®º"
        if critical_reviews:
            log_message += f" (ID: {[r.get('review_id') for r in critical_reviews]})"
        log_message += f" | LLMé”™è¯¯: {str(e)[:50]}"
        
        return {
            "critical_reviews": critical_reviews,
            "logs": [log_message]
        }


def node_rag_analysis(state: ReviewState) -> ReviewState:
    """
    èŠ‚ç‚¹ 3: RAG å½’å› åˆ†æ
    æš‚æ—¶ä½¿ç”¨åŸºç¡€é€»è¾‘ï¼Œç®€å•è°ƒç”¨ LLM ç”Ÿæˆå½’å› 
    """
    llm = init_llm()
    critical_reviews = state.get("critical_reviews", [])
    
    if not critical_reviews:
        log_message = "âš ï¸ RAG åˆ†æèŠ‚ç‚¹ï¼šæ— é«˜å±è¯„è®ºéœ€è¦åˆ†æ"
        return {
            "rag_analysis_results": [],
            "logs": [log_message]
        }
    
    rag_results = []
    
    for review in critical_reviews:
        review_text = review.get("review_text", "")
        review_id = review.get("review_id")
        
        # åŸºç¡€ RAG åˆ†æï¼ˆå ä½é€»è¾‘ï¼‰
        # TODO: åç»­å¯ä»¥æ¥å…¥çœŸå®çš„å‘é‡æ£€ç´¢
        rag_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·åé¦ˆï¼Œåˆ¤æ–­è¿™æ˜¯ç”¨æˆ·ä½¿ç”¨é—®é¢˜è¿˜æ˜¯äº§å“ç¼ºé™·ã€‚

ç”¨æˆ·åé¦ˆï¼š{review_text}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "review_id": {review_id},
  "conclusion": "âœ… äº§å“å·²çŸ¥å±€é™" æˆ– "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" æˆ– "â“ ç”¨æˆ·ä½¿ç”¨é—®é¢˜",
  "reason": "åˆ†æåŸå› "
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚"""
        
        try:
            response = llm.invoke([HumanMessage(content=rag_prompt)])
            answer = response.content if hasattr(response, 'content') else str(response)
            
            # è§£æ JSON
            json_str = answer.strip()
            if json_str.startswith("```json"):
                json_str = json_str[7:]
            elif json_str.startswith("```"):
                json_str = json_str[3:]
            if json_str.endswith("```"):
                json_str = json_str[:-3]
            json_str = json_str.strip()
            
            result = json.loads(json_str)
            rag_results.append({
                "review_id": review_id,
                "review_text": review_text,
                "conclusion": result.get("conclusion", "â“ éœ€è¦äººå·¥åˆ¤æ–­"),
                "reason": result.get("reason", "")
            })
            
        except Exception as e:
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            rag_results.append({
                "review_id": review_id,
                "review_text": review_text,
                "conclusion": "â“ éœ€è¦äººå·¥åˆ¤æ–­",
                "reason": f"LLM åˆ†æå¤±è´¥: {str(e)}"
            })
    
    log_message = f"ğŸ“„ RAG åˆ†æèŠ‚ç‚¹ï¼šå®Œæˆ {len(rag_results)} æ¡è¯„è®ºçš„å½’å› åˆ†æ"
    
    return {
        "rag_analysis_results": rag_results,
        "logs": [log_message]
    }


def node_action_gen(state: ReviewState) -> ReviewState:
    """
    èŠ‚ç‚¹ 4: ç”Ÿæˆè¡ŒåŠ¨å»ºè®®
    åŸºäºå½’å› ç”Ÿæˆ JSON æ ¼å¼çš„ Action
    """
    llm = init_llm()
    rag_results = state.get("rag_analysis_results", [])
    
    if not rag_results:
        log_message = "âš ï¸ è¡ŒåŠ¨ç”ŸæˆèŠ‚ç‚¹ï¼šæ— å½’å› ç»“æœéœ€è¦ç”Ÿæˆè¡ŒåŠ¨"
        return {
            "action_plans": [],
            "logs": [log_message]
        }
    
    action_plans = []
    
    for rag_result in rag_results:
        review_text = rag_result.get("review_text", "")
        conclusion = rag_result.get("conclusion", "")
        reason = rag_result.get("reason", "")
        
        # ç”Ÿæˆè¡ŒåŠ¨å»ºè®®
        action_prompt = f"""åŸºäºä»¥ä¸‹å½’å› åˆ†æï¼Œç”Ÿæˆå…·ä½“çš„è¡ŒåŠ¨å»ºè®®ã€‚

ç”¨æˆ·åé¦ˆï¼š{review_text}
å½’å› ç»“è®ºï¼š{conclusion}
åˆ†æåŸå› ï¼š{reason}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "action_type": "Jira Ticket" æˆ– "Doc Update" æˆ– "Email Draft" æˆ– "Meeting",
  "title": "è¡ŒåŠ¨æ ‡é¢˜",
  "content": "è¯¦ç»†å†…å®¹",
  "priority": "High" æˆ– "Medium" æˆ– "Low"
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚"""
        
        try:
            response = llm.invoke([HumanMessage(content=action_prompt)])
            answer = response.content if hasattr(response, 'content') else str(response)
            
            # è§£æ JSON
            json_str = answer.strip()
            if json_str.startswith("```json"):
                json_str = json_str[7:]
            elif json_str.startswith("```"):
                json_str = json_str[3:]
            if json_str.endswith("```"):
                json_str = json_str[:-3]
            json_str = json_str.strip()
            
            result = json.loads(json_str)
            action_plans.append({
                "review_id": rag_result.get("review_id"),
                "action_type": result.get("action_type", "Jira Ticket"),
                "title": result.get("title", ""),
                "content": result.get("content", ""),
                "priority": result.get("priority", "Medium")
            })
            
        except Exception as e:
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            action_plans.append({
                "review_id": rag_result.get("review_id"),
                "action_type": "Jira Ticket",
                "title": f"å¤„ç†è¯„è®º {rag_result.get('review_id')} çš„é—®é¢˜",
                "content": review_text,
                "priority": "Medium"
            })
    
    log_message = f"ğŸ’¡ è¡ŒåŠ¨ç”ŸæˆèŠ‚ç‚¹ï¼šç”Ÿæˆ {len(action_plans)} ä¸ªè¡ŒåŠ¨å»ºè®®"
    
    return {
        "action_plans": action_plans,
        "logs": [log_message]
    }


# ==================== æ¡ä»¶è·¯ç”± ====================
def should_continue_analysis(state: ReviewState) -> Literal["rag_analysis", "end"]:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­ RAG åˆ†æ"""
    critical_reviews = state.get("critical_reviews", [])
    if len(critical_reviews) > 0:
        return "rag_analysis"
    return "end"


# ==================== æ„å»ºå›¾ ====================
def build_graph():
    """æ„å»º LangGraph å·¥ä½œæµ"""
    # åˆ›å»ºçŠ¶æ€å›¾ï¼ŒæŒ‡å®š reducer
    workflow = StateGraph(ReviewState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("monitor", node_monitor)
    workflow.add_node("filter", node_filter)
    workflow.add_node("rag_analysis", node_rag_analysis)
    workflow.add_node("action_gen", node_action_gen)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("monitor")
    
    # æ·»åŠ è¾¹
    workflow.add_edge("monitor", "filter")
    
    # æ¡ä»¶è·¯ç”±ï¼šfilter ååˆ¤æ–­æ˜¯å¦ç»§ç»­
    workflow.add_conditional_edges(
        "filter",
        should_continue_analysis,
        {
            "rag_analysis": "rag_analysis",
            "end": END
        }
    )
    
    workflow.add_edge("rag_analysis", "action_gen")
    workflow.add_edge("action_gen", END)
    
    # ç¼–è¯‘å›¾
    graph_app = workflow.compile()
    
    return graph_app


# ==================== å¯¼å‡º ====================
# åˆ›å»ºå…¨å±€å›¾å®ä¾‹
graph_app = build_graph()


if __name__ == "__main__":
    # æµ‹è¯•å·¥ä½œæµ
    initial_state = {
        "raw_reviews": [],
        "critical_reviews": [],
        "rag_analysis_results": [],
        "action_plans": [],
        "logs": []
    }
    
    print("ğŸš€ å¼€å§‹è¿è¡Œ ReviewOps å·¥ä½œæµ...")
    result = graph_app.invoke(initial_state)
    
    print("\nğŸ“Š æœ€ç»ˆçŠ¶æ€ï¼š")
    print(f"åŸå§‹è¯„è®ºæ•°: {len(result.get('raw_reviews', []))}")
    print(f"é«˜å±è¯„è®ºæ•°: {len(result.get('critical_reviews', []))}")
    print(f"å½’å› ç»“æœæ•°: {len(result.get('rag_analysis_results', []))}")
    print(f"è¡ŒåŠ¨å»ºè®®æ•°: {len(result.get('action_plans', []))}")
    
    print("\nğŸ“ æ—¥å¿—ï¼š")
    for log in result.get("logs", []):
        print(f"  {log}")
    
    print("\nğŸ’¡ è¡ŒåŠ¨å»ºè®®ï¼š")
    for action in result.get("action_plans", []):
        print(f"  - {action.get('title')} ({action.get('action_type')})")

