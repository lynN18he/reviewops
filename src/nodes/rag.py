"""
RAG åˆ†æèŠ‚ç‚¹ï¼šåŸºäºäº§å“è¯´æ˜ä¹¦è¿›è¡Œå½’å› åˆ†æ
"""

import json
import os
from src.state import ReviewState
from src.utils import init_llm
from langchain_core.messages import HumanMessage


def node_rag_analysis(state: ReviewState) -> ReviewState:
    """
    èŠ‚ç‚¹ 3: RAG å½’å› åˆ†æ
    æ¥å…¥çœŸå®çš„å‘é‡æ£€ç´¢ï¼ŒåŸºäºäº§å“è¯´æ˜ä¹¦è¿›è¡Œå½’å› åˆ†æ
    """
    llm = init_llm()
    critical_reviews = state.get("critical_reviews", [])
    
    if not critical_reviews:
        log_message = "âš ï¸ RAG åˆ†æèŠ‚ç‚¹ï¼šæ— é«˜å±è¯„è®ºéœ€è¦åˆ†æ"
        return {
            "rag_analysis_results": [],
            "logs": [log_message]
        }
    
    # åˆå§‹åŒ–å‘é‡åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
    vectorstore = None
    try:
        from langchain_community.vectorstores import Chroma
        from langchain_community.embeddings import DashScopeEmbeddings
        from src.config import EmbeddingConfig, VectorStoreConfig
        
        api_key = EmbeddingConfig.get_api_key()
        if api_key:
            embeddings = DashScopeEmbeddings(
                model=EmbeddingConfig.MODEL,
                dashscope_api_key=api_key
            )
            vectorstore = Chroma(
                persist_directory=VectorStoreConfig.PERSIST_DIRECTORY,
                embedding_function=embeddings
            )
    except Exception as e:
        log_message = f"âš ï¸ å‘é‡åº“åˆå§‹åŒ–å¤±è´¥: {str(e)[:50]}"
        # ç»§ç»­æ‰§è¡Œï¼Œä½¿ç”¨é™çº§é€»è¾‘
    
    rag_results = []
    
    for review in critical_reviews:
        review_text = review.get("review_text", "")
        review_id = review.get("review_id", "")
        
        try:
            # å¦‚æœæœ‰å‘é‡åº“ï¼Œä½¿ç”¨çœŸå®çš„ RAG æ£€ç´¢
            if vectorstore:
                # æ„å»ºæŸ¥è¯¢
                query = f"ç”¨æˆ·åé¦ˆï¼š{review_text}ã€‚è¯·åˆ†æè¿™æ˜¯äº§å“å·²çŸ¥å±€é™è¿˜æ˜¯æ–°é—®é¢˜ã€‚"
                
                # æ£€ç´¢ç›¸å…³æ–‡æ¡£
                try:
                    from src.config import VectorStoreConfig
                    docs_with_scores = vectorstore.similarity_search_with_score(query, k=VectorStoreConfig.TOP_K)
                    # è¿‡æ»¤ä½ç›¸å…³æ€§ç»“æœ
                    relevant_docs = []
                    for doc, distance in docs_with_scores:
                        if distance < VectorStoreConfig.DISTANCE_THRESHOLD:
                            relevant_docs.append(doc)
                    
                    if relevant_docs:
                        # æ„å»ºä¸Šä¸‹æ–‡
                        max_docs = min(VectorStoreConfig.MAX_DOCS_IN_CONTEXT, len(relevant_docs))
                        context = "\n\n".join([
                            doc.page_content[:VectorStoreConfig.MAX_CONTEXT_LENGTH] 
                            for doc in relevant_docs[:max_docs]
                        ])
                        
                        # ä½¿ç”¨ RAG å¢å¼ºçš„ Prompt
                        rag_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·åé¦ˆå’Œäº§å“è¯´æ˜ä¹¦ï¼Œè¿›è¡Œå‡†ç¡®çš„å½’å› åˆ†æã€‚

äº§å“è¯´æ˜ä¹¦ç›¸å…³å†…å®¹ï¼š
{context}

ç”¨æˆ·åé¦ˆï¼š{review_text}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "review_id": "{review_id}",
  "conclusion": "âœ… äº§å“å·²çŸ¥å±€é™" æˆ– "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" æˆ– "â“ ç”¨æˆ·ä½¿ç”¨é—®é¢˜",
  "reason": "åŸºäºäº§å“è¯´æ˜ä¹¦çš„åˆ†æåŸå› ",
  "evidence": "ä»è¯´æ˜ä¹¦ä¸­æå–çš„ç›¸å…³è¯æ®ç‰‡æ®µ"
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚"""
                    else:
                        # æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ
                        rag_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·åé¦ˆï¼Œåˆ¤æ–­è¿™æ˜¯ç”¨æˆ·ä½¿ç”¨é—®é¢˜è¿˜æ˜¯äº§å“ç¼ºé™·ã€‚

ç”¨æˆ·åé¦ˆï¼š{review_text}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "review_id": "{review_id}",
  "conclusion": "âœ… äº§å“å·²çŸ¥å±€é™" æˆ– "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" æˆ– "â“ ç”¨æˆ·ä½¿ç”¨é—®é¢˜",
  "reason": "åˆ†æåŸå› ",
  "evidence": "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°ç›¸å…³æè¿°"
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚"""
                except Exception as e:
                    # å‘é‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ
                    rag_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·åé¦ˆï¼Œåˆ¤æ–­è¿™æ˜¯ç”¨æˆ·ä½¿ç”¨é—®é¢˜è¿˜æ˜¯äº§å“ç¼ºé™·ã€‚

ç”¨æˆ·åé¦ˆï¼š{review_text}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "review_id": "{review_id}",
  "conclusion": "âœ… äº§å“å·²çŸ¥å±€é™" æˆ– "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" æˆ– "â“ ç”¨æˆ·ä½¿ç”¨é—®é¢˜",
  "reason": "åˆ†æåŸå› ",
  "evidence": "å‘é‡æ£€ç´¢å¤±è´¥: {str(e)[:50]}"
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚"""
            else:
                # æ²¡æœ‰å‘é‡åº“ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ
                rag_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·åé¦ˆï¼Œåˆ¤æ–­è¿™æ˜¯ç”¨æˆ·ä½¿ç”¨é—®é¢˜è¿˜æ˜¯äº§å“ç¼ºé™·ã€‚

ç”¨æˆ·åé¦ˆï¼š{review_text}

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "review_id": "{review_id}",
  "conclusion": "âœ… äº§å“å·²çŸ¥å±€é™" æˆ– "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥" æˆ– "â“ ç”¨æˆ·ä½¿ç”¨é—®é¢˜",
  "reason": "åˆ†æåŸå› ",
  "evidence": "å‘é‡åº“æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ"
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚"""
            
            # è°ƒç”¨ LLM
            response = llm.invoke([HumanMessage(content=rag_prompt)])
            answer = response.content if hasattr(response, 'content') else str(response)
            
            # è§£æ JSONï¼ˆæ”¹è¿›çš„è§£æé€»è¾‘ï¼‰
            json_str = answer.strip()
            
            # ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
            if json_str.startswith("```json"):
                json_str = json_str[7:]
            elif json_str.startswith("```"):
                json_str = json_str[3:]
            if json_str.endswith("```"):
                json_str = json_str[:-3]
            json_str = json_str.strip()
            
            # å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„é¢å¤–æ–‡æœ¬ï¼‰
            if "{" in json_str and "}" in json_str:
                start_idx = json_str.find("{")
                end_idx = json_str.rfind("}") + 1
                json_str = json_str[start_idx:end_idx]
            
            result = json.loads(json_str)
            
            rag_results.append({
                "review_id": review_id,
                "review_text": review_text,
                "conclusion": result.get("conclusion", "â“ éœ€è¦äººå·¥åˆ¤æ–­"),
                "reason": result.get("reason", ""),
                "evidence": result.get("evidence", "")
            })
            
        except json.JSONDecodeError as e:
            # JSON è§£æå¤±è´¥ï¼Œå°è¯•æå–å…³é”®ä¿¡æ¯
            rag_results.append({
                "review_id": review_id,
                "review_text": review_text,
                "conclusion": "â“ éœ€è¦äººå·¥åˆ¤æ–­",
                "reason": f"JSON è§£æå¤±è´¥: {str(e)[:100]}",
                "evidence": f"LLM è¿”å›å†…å®¹: {answer[:200]}"
            })
        except Exception as e:
            # å…¶ä»–é”™è¯¯
            rag_results.append({
                "review_id": review_id,
                "review_text": review_text,
                "conclusion": "â“ éœ€è¦äººå·¥åˆ¤æ–­",
                "reason": f"RAG åˆ†æå¤±è´¥: {str(e)[:100]}",
                "evidence": ""
            })
    
    log_message = f"ğŸ“„ RAG åˆ†æèŠ‚ç‚¹ï¼šå®Œæˆ {len(rag_results)} æ¡è¯„è®ºçš„å½’å› åˆ†æ"
    if vectorstore:
        log_message += "ï¼ˆå·²ä½¿ç”¨å‘é‡æ£€ç´¢ï¼‰"
    else:
        log_message += "ï¼ˆä½¿ç”¨åŸºç¡€åˆ†æï¼‰"
    
    return {
        "rag_analysis_results": rag_results,
        "logs": [log_message]
    }

