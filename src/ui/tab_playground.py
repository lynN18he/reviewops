"""
å•æ¡å½’å› å®éªŒå®¤ Tab
åŒ…å«å•æ¡è¯„è®ºè¾“å…¥ã€RAG åˆ†æã€è¡ŒåŠ¨å»ºè®®ç”Ÿæˆç­‰æ‰€æœ‰é€»è¾‘
"""

import streamlit as st
import random
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.chat_models import ChatTongyi
from langchain_community.vectorstores import Chroma


def init_vectorstore(api_key):
    """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
    if not api_key:
        return None
    
    try:
        embeddings = DashScopeEmbeddings(
            model="text-embedding-v3",  # ä¸ injest.py ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ v3 æ¨¡å‹ï¼ˆ1536 ç»´ï¼‰
            dashscope_api_key=api_key
        )
        
        vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=embeddings
        )
        return vectorstore
    except Exception as e:
        st.error(f"å‘é‡åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


@st.cache_resource
def init_llm(api_key):
    """åˆå§‹åŒ– LLM"""
    if not api_key:
        return None
    
    try:
        llm = ChatTongyi(
            model="qwen-plus",
            temperature=0,
            dashscope_api_key=api_key
        )
        return llm
    except Exception as e:
        st.error(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def perform_rag_query(vectorstore, llm, question):
    """æ‰§è¡Œ RAG æŸ¥è¯¢ï¼šæ£€ç´¢ + ç”Ÿæˆ"""
    if not vectorstore or not llm:
        return None, []
    
    try:
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆä½¿ç”¨ similarity_search_with_score è·å–è·ç¦»åˆ†æ•°ï¼‰
        # ä½¿ç”¨æ›´å¤§çš„ k å€¼ï¼Œç„¶åå»é‡å’Œè¿‡æ»¤
        try:
            docs_with_scores = vectorstore.similarity_search_with_score(question, k=10)
        except:
            # å¦‚æœä¸æ”¯æŒ similarity_search_with_scoreï¼Œå›é€€åˆ°æ™®é€šæœç´¢
            docs = vectorstore.similarity_search(question, k=5)
            # ç®€å•å»é‡ï¼Œè¿”å›æ‰€æœ‰ä¸é‡å¤çš„æ–‡æ¡£
            unique_docs = []
            seen_contents = set()
            for doc in docs:
                content_fingerprint = doc.page_content[:150].strip()
                if content_fingerprint not in seen_contents:
                    seen_contents.add(content_fingerprint)
                    unique_docs.append(doc)
            docs = unique_docs  # è¿”å›æ‰€æœ‰å»é‡åçš„æ–‡æ¡£ï¼Œä¸é™åˆ¶æ•°é‡
        else:
            # 2. å»é‡ï¼šåŸºäºæ–‡æ¡£å†…å®¹çš„ç›¸ä¼¼åº¦å»é‡
            # ChromaDB è¿”å›çš„æ˜¯è·ç¦»ï¼ˆdistanceï¼‰ï¼Œè¶Šå°è¶Šç›¸ä¼¼
            # é€šå¸¸è·ç¦» < 1.5 è¡¨ç¤ºæ¯”è¾ƒç›¸å…³
            unique_docs = []
            seen_contents = set()
            max_distance = 1.5  # æœ€å¤§è·ç¦»é˜ˆå€¼ï¼ˆæ ¹æ®å®é™…è°ƒæ•´ï¼‰
            
            for doc, distance in docs_with_scores:
                # è¿‡æ»¤è·ç¦»è¿‡å¤§çš„ç»“æœï¼ˆç›¸ä¼¼åº¦å¤ªä½ï¼‰
                if distance > max_distance:
                    continue
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦é‡å¤ï¼ˆä½¿ç”¨å‰150ä¸ªå­—ç¬¦ä½œä¸ºæŒ‡çº¹ï¼Œæ›´å‡†ç¡®ï¼‰
                content_fingerprint = doc.page_content[:150].strip()
                if content_fingerprint not in seen_contents:
                    seen_contents.add(content_fingerprint)
                    unique_docs.append(doc)
                    # ä¸å†é™åˆ¶æ•°é‡ï¼Œè¿”å›æ‰€æœ‰ç›¸å…³ä¸”ä¸é‡å¤çš„æ–‡æ¡£
            
            docs = unique_docs  # è¿”å›æ‰€æœ‰ç›¸å…³ä¸”å»é‡åçš„æ–‡æ¡£
        
        # 3. æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([doc.page_content for doc in docs])
        
        # 3. æ„å»º Prompt
        from langchain_core.messages import HumanMessage, SystemMessage
        
        system_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·åé¦ˆå’Œäº§å“è¯´æ˜ä¹¦ï¼Œè¿›è¡Œå‡†ç¡®çš„å½’å› åˆ†æã€‚

è¯·åŸºäºä»¥ä¸‹äº§å“è¯´æ˜ä¹¦å†…å®¹ï¼Œåˆ†æç”¨æˆ·åé¦ˆé—®é¢˜ï¼š
{context}

å›ç­”æ ¼å¼ï¼š
- è¯´æ˜ä¹¦å¯¹åº”å‚æ•°ï¼š[ä»äº§å“è¯´æ˜ä¹¦ä¸­æå–çš„ç›¸å…³å†…å®¹]
- AI åˆ¤å®šç»“è®ºï¼š[ä½ çš„åˆ¤æ–­ï¼Œå¦‚æœæ˜¯å·²çŸ¥å±€é™ç”¨âœ…ï¼Œå¦‚æœæ˜¯æ–°é—®é¢˜ç”¨âš ï¸ï¼Œå¦‚æœæ˜¯ç”¨æˆ·è¯¯ç”¨ç”¨â“]

å›ç­”ï¼š"""
        
        human_template = "ç”¨æˆ·åé¦ˆï¼š{question}"
        
        system_prompt = SystemMessage(content=system_template.format(context=context))
        human_prompt = HumanMessage(content=human_template.format(question=question))
        
        # 4. è°ƒç”¨ LLM
        response = llm.invoke([system_prompt, human_prompt])
        
        # 5. æå–å›ç­”
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
        
        return answer, docs
        
    except Exception as e:
        st.error(f"RAG æŸ¥è¯¢å¤±è´¥: {e}")
        return None, []


def match_with_spec(complaint, qa_chain=None):
    """å°†ç”¨æˆ·æŠ±æ€¨ä¸äº§å“è¯´æ˜ä¹¦è¿›è¡ŒåŒ¹é…ï¼ˆä½¿ç”¨ RAGï¼‰"""
    
    # å¦‚æœæ²¡æœ‰ RAG é“¾ï¼Œä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…ä½œä¸ºåå¤‡
    if not qa_chain:
        if 'ä¸­æ–‡æ’­å®¢' in complaint or 'ä¸­æ–‡' in complaint:
            spec_match = "éŸ³é¢‘ä¸è¯­è¨€é™åˆ¶ï¼šAudio Overview ç›®å‰å¼ºè°ƒä¸ºå®éªŒæ€§åŠŸèƒ½...ä¸­æ–‡æ’­å®¢å¼è¾“å‡ºä½“éªŒæ˜æ˜¾å¼±äºè‹±æ–‡"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨ä¸­æ–‡æ”¯æŒæœ‰é™"
        elif 'PDF' in complaint or 'å›¾è¡¨' in complaint:
            spec_match = "å†…å®¹ä¸æ–‡ä»¶é™åˆ¶ï¼šå¯¹çº¯å›¾ç‰‡ PDFã€å¤æ‚è¡¨æ ¼æˆ–å›¾åƒä¿¡æ¯æ”¯æŒæœ‰é™ï¼Œå›¾è¡¨å’Œå›¾åƒå‹ PDF åœ¨è§£æå’Œæ£€ç´¢æ—¶ä»å¯èƒ½ä¸¢å¤±æˆ–å¼±åŒ–"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨å›¾è¡¨è§£æå—é™"
        else:
            spec_match = "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°å¯¹åº”æè¿°"
            conclusion = "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥ - å¯èƒ½æ˜¯æ–°å‘ç°çš„é—®é¢˜"
        return spec_match, conclusion, []
    
    # ä½¿ç”¨ RAG è¿›è¡ŒçœŸå®æ£€ç´¢å’Œåˆ†æ
    try:
        query = f"ç”¨æˆ·åé¦ˆï¼š{complaint}ã€‚è¯·åˆ†æè¿™æ˜¯äº§å“å·²çŸ¥å±€é™è¿˜æ˜¯æ–°é—®é¢˜ã€‚"
        answer, source_docs = perform_rag_query(qa_chain['vectorstore'], qa_chain['llm'], query)
        
        if not answer:
            raise Exception("RAG æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
        
        # è§£æå›ç­”ï¼Œæå–è¯´æ˜ä¹¦å‚æ•°å’Œç»“è®º
        spec_match = ""
        conclusion = ""
        
        # ä»å›ç­”ä¸­æå–ä¿¡æ¯
        if "è¯´æ˜ä¹¦å¯¹åº”å‚æ•°" in answer:
            parts = answer.split("è¯´æ˜ä¹¦å¯¹åº”å‚æ•°ï¼š")
            if len(parts) > 1:
                spec_part = parts[1].split("AI åˆ¤å®šç»“è®ºï¼š")[0].strip()
                spec_match = spec_part if spec_part else "æœªæ‰¾åˆ°ç›¸å…³è¯´æ˜"
        else:
            spec_match = "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°å¯¹åº”æè¿°"
        
        if "AI åˆ¤å®šç»“è®º" in answer:
            conclusion = answer.split("AI åˆ¤å®šç»“è®ºï¼š")[-1].strip()
        else:
            # ä»å›ç­”ä¸­æ¨æ–­ç»“è®º
            if "å·²çŸ¥å±€é™" in answer or "âœ…" in answer:
                conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - " + answer[:50]
            elif "æ–°é—®é¢˜" in answer or "âš ï¸" in answer:
                conclusion = "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥ - " + answer[:50]
            else:
                conclusion = "â“ éœ€è¦äººå·¥åˆ¤æ–­ - " + answer[:50]
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°ï¼Œä½¿ç”¨æºæ–‡æ¡£å†…å®¹
        if not spec_match and source_docs:
            spec_match = "\n\n".join([doc.page_content[:200] + "..." for doc in source_docs[:2]])
        
        # è¿”å›æºæ–‡æ¡£å†…å®¹ç”¨äºå±•ç¤ºï¼ˆå»é‡ï¼‰
        source_contents = []
        seen_contents = set()
        for doc in source_docs:
            content = doc.page_content
            # ä½¿ç”¨å‰100ä¸ªå­—ç¬¦ä½œä¸ºæŒ‡çº¹å»é‡
            fingerprint = content[:100].strip()
            if fingerprint not in seen_contents:
                seen_contents.add(fingerprint)
                source_contents.append(content)
        
        return spec_match, conclusion, source_contents
        
    except Exception as e:
        st.warning(f"RAG åˆ†æå‡ºé”™: {e}ï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ")
        # åå¤‡æ–¹æ¡ˆ
        if 'ä¸­æ–‡æ’­å®¢' in complaint or 'ä¸­æ–‡' in complaint:
            spec_match = "éŸ³é¢‘ä¸è¯­è¨€é™åˆ¶ï¼šAudio Overview ç›®å‰å¼ºè°ƒä¸ºå®éªŒæ€§åŠŸèƒ½...ä¸­æ–‡æ’­å®¢å¼è¾“å‡ºä½“éªŒæ˜æ˜¾å¼±äºè‹±æ–‡"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨ä¸­æ–‡æ”¯æŒæœ‰é™"
        elif 'PDF' in complaint or 'å›¾è¡¨' in complaint:
            spec_match = "å†…å®¹ä¸æ–‡ä»¶é™åˆ¶ï¼šå¯¹çº¯å›¾ç‰‡ PDFã€å¤æ‚è¡¨æ ¼æˆ–å›¾åƒä¿¡æ¯æ”¯æŒæœ‰é™ï¼Œå›¾è¡¨å’Œå›¾åƒå‹ PDF åœ¨è§£æå’Œæ£€ç´¢æ—¶ä»å¯èƒ½ä¸¢å¤±æˆ–å¼±åŒ–"
            conclusion = "âœ… äº§å“å·²çŸ¥å±€é™ - è¯´æ˜ä¹¦å·²æ˜ç¡®æ ‡æ³¨å›¾è¡¨è§£æå—é™"
        else:
            spec_match = "æœªåœ¨è¯´æ˜ä¹¦ä¸­æ‰¾åˆ°å¯¹åº”æè¿°"
            conclusion = "âš ï¸ éœ€è¿›ä¸€æ­¥è°ƒæŸ¥ - å¯èƒ½æ˜¯æ–°å‘ç°çš„é—®é¢˜"
        return spec_match, conclusion, []


def generate_action_plan(topic_name: str, rag_conclusion: str, user_complaints: list, llm):
    """
    ä½¿ç”¨ LLM æ ¹æ® RAG åˆ†æç»“æœåŠ¨æ€ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’
    
    Args:
        topic_name: é—®é¢˜èšç±»åç§°
        rag_conclusion: RAG åˆ†æå‡ºçš„å½’å› ç»“è®º
        user_complaints: å…¸å‹ç”¨æˆ·åŸè¯åˆ—è¡¨
        llm: LangChain LLM å®ä¾‹
    
    Returns:
        dict: ActionPlan å¯¹è±¡ï¼ˆåŒ…å« action_type, title, content, priorityï¼‰
    """
    if not llm:
        return None
    
    import json
    import re
    from langchain_core.messages import HumanMessage
    
    # æ„å»ºç”¨æˆ·æŠ±æ€¨æ‘˜è¦
    complaints_text = "\n".join([f"- {complaint}" for complaint in user_complaints[:5]])
    
    # æ„å»º Prompt
    prompt_template = """ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®é—®é¢˜æ€§è´¨åšå‡ºå†³ç­–çš„äº§å“ç»ç†ã€‚

è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’ï¼š

**é—®é¢˜ç±»å‹ï¼š** {topic_name}

**RAG å½’å› ç»“è®ºï¼š** {rag_conclusion}

**å…¸å‹ç”¨æˆ·åé¦ˆï¼š**
{complaints}

**å†³ç­–è§„åˆ™ï¼š**
- å¦‚æœå½’å› æ˜¯ **äº§å“ç¼ºé™·/Bug** -> ç”Ÿæˆ Jira Ticketï¼ŒåŒ…å«æ ‡é¢˜ã€æè¿°ã€å¤ç°æ­¥éª¤ã€ä¼˜å…ˆçº§
- å¦‚æœå½’å› æ˜¯ **ç”¨æˆ·è¯¯æ“ä½œ/æ–‡æ¡£ä¸æ¸…** -> ç”Ÿæˆ Doc Updateï¼ˆæ›´æ–°è¯´æ˜ä¹¦ï¼‰æˆ– Email Draftï¼ˆå®¢æœè¯æœ¯ï¼‰
- å¦‚æœå½’å› æ˜¯ **ç‰©æµ/æœåŠ¡é—®é¢˜** -> ç”Ÿæˆ Email Draftï¼ˆç»™ç‰©æµå•†æˆ–å®¢æœä¸»ç®¡ï¼‰
- å¦‚æœå½’å› æ˜¯ **å¤æ‚é—®é¢˜éœ€è¦è®¨è®º** -> ç”Ÿæˆ Meetingï¼ˆä¼šè®®å®‰æ’ï¼‰

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ï¼š

{{
  "action_type": "Jira Ticket" | "Doc Update" | "Email Draft" | "Meeting",
  "title": "è¡ŒåŠ¨çš„ç®€çŸ­æ ‡é¢˜ï¼ˆå¦‚ï¼šåˆ›å»º P0 çº§ Jira å·¥å•ï¼šä¿®å¤äº‘å°æŠ–åŠ¨ï¼‰",
  "content": "è¡ŒåŠ¨çš„è¯¦ç»†å†…å®¹ï¼ˆå¦‚å·¥å•çš„ Description æˆ–é‚®ä»¶çš„æ­£æ–‡ï¼Œè¦å…·ä½“å¯æ‰§è¡Œï¼‰",
  "priority": "High" | "Medium" | "Low"
}}

è¯·ç›´æ¥è¿”å› JSON æ ¼å¼ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—ï¼š"""
    
    try:
        prompt = prompt_template.format(
            topic_name=topic_name,
            rag_conclusion=rag_conclusion,
            complaints=complaints_text
        )
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        # æå–å›ç­”
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
        
        # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
        json_str = answer.strip()
        
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if json_str.startswith("```json"):
            json_str = json_str[7:]
        elif json_str.startswith("```"):
            json_str = json_str[3:]
        if json_str.endswith("```"):
            json_str = json_str[:-3]
        json_str = json_str.strip()
        
        # è§£æ JSON
        try:
            result = json.loads(json_str)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['action_type', 'title', 'content', 'priority']
            if all(field in result for field in required_fields):
                # éªŒè¯ action_type
                valid_types = ['Jira Ticket', 'Doc Update', 'Email Draft', 'Meeting']
                if result['action_type'] not in valid_types:
                    result['action_type'] = 'Doc Update'  # é»˜è®¤å€¼
                
                # éªŒè¯ priority
                valid_priorities = ['High', 'Medium', 'Low']
                if result['priority'] not in valid_priorities:
                    result['priority'] = 'Medium'  # é»˜è®¤å€¼
                
                return result
            else:
                st.warning(f"LLM è¿”å›çš„ JSON ç¼ºå°‘å¿…éœ€å­—æ®µã€‚åŸå§‹å“åº”ï¼š\n{answer[:500]}")
                return None
                
        except json.JSONDecodeError as e:
            st.warning(f"JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {e}")
            # å°è¯•æå– JSON å¯¹è±¡
            json_match = re.search(r'\{.*\}', json_str, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    return result
                except:
                    pass
            
            st.error(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSONã€‚åŸå§‹å“åº”ï¼š\n{answer[:500]}")
            return None
            
    except Exception as e:
        st.error(f"ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’æ—¶å‡ºé”™: {e}")
        return None


def render_tab(api_key):
    """
    æ¸²æŸ“å•æ¡å½’å› å®éªŒå®¤ Tab
    
    Args:
        api_key: DashScope API Key
    """
    st.markdown("### ğŸ”¬ å•æ¡è¯„è®ºå½’å› åˆ†æ")
    st.caption("è¾“å…¥å•æ¡ç”¨æˆ·è¯„è®ºï¼Œè¿›è¡Œæ·±åº¦ RAG å½’å› åˆ†æ")
    
    # å•æ¡è¯„è®ºè¾“å…¥
    user_input = st.text_area(
        "ğŸ“ è¯·è¾“å…¥ç”¨æˆ·è¯„è®º",
        placeholder="ä¾‹å¦‚ï¼šå¤œé—´é£è¡Œæ—¶é¿éšœåŠŸèƒ½å®Œå…¨å¤±æ•ˆï¼Œå·®ç‚¹æ’å¢™...",
        height=100,
        key="manual_review_input"
    )
    
    analyze_button = st.button("ğŸš€ å¼€å§‹å½’å› åˆ†æ", use_container_width=True, key="analyze_btn_manual")
    
    if analyze_button:
        # æ£€æŸ¥è¾“å…¥
        if not user_input or not user_input.strip():
            st.warning("âš ï¸ è¯·è¾“å…¥ç”¨æˆ·è¯„è®º")
            st.stop()
        
        # æ£€æŸ¥ API Key
        if not api_key:
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® DashScope API Key")
            st.stop()
        
        # åˆå§‹åŒ– RAG ç»„ä»¶
        with st.spinner("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– RAG ç³»ç»Ÿ..."):
            vectorstore = init_vectorstore(api_key)
            llm = init_llm(api_key)
            
            if not vectorstore or not llm:
                st.error("âŒ RAG ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key å’Œå‘é‡åº“")
                st.stop()
        
        # æ‰§è¡Œ RAG åˆ†æ
        with st.spinner("ğŸ§  AI æ­£åœ¨åˆ†æä¸­..."):
            spec_match, conclusion, source_docs = match_with_spec(
                user_input,
                qa_chain={'vectorstore': vectorstore, 'llm': llm}
            )
        
        st.success("âœ… åˆ†æå®Œæˆï¼")
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        
        col_left, col_right = st.columns([1, 1])
        
        with col_left:
            st.markdown("##### ğŸ’¬ ç”¨æˆ·è¯„è®º")
            st.info(user_input)
            
            st.markdown("##### ğŸ¤– AI åˆ¤å®šç»“è®º")
            if "âœ…" in conclusion:
                st.success(conclusion)
            elif "âš ï¸" in conclusion:
                st.warning(conclusion)
            elif "â“" in conclusion:
                st.info(conclusion)
            else:
                st.info(conclusion)
        
        with col_right:
            st.markdown("##### ğŸ“– è¯´æ˜ä¹¦å¯¹åº”å‚æ•°")
            if len(spec_match) > 500:
                with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´è¯´æ˜ä¹¦å†…å®¹", expanded=True):
                    st.markdown(spec_match)
            else:
                st.markdown(f"<div style='background-color: #f0f9ff; padding: 1rem; border-radius: 8px; border-left: 4px solid #0ea5e9;'>{spec_match}</div>", unsafe_allow_html=True)
            
            # æ˜¾ç¤ºè¯æ®æ¥æº
            if source_docs:
                st.markdown("")
                with st.expander(f"ğŸ“š æ£€ç´¢åˆ°çš„è¯æ®æ¥æº ({len(source_docs)} æ¡)", expanded=False):
                    for i, doc in enumerate(source_docs, 1):
                        st.markdown(f"**è¯æ® {i}:**")
                        st.text_area(
                            label="",
                            value=doc,
                            height=150,
                            key=f"manual_source_doc_{i}",
                            disabled=True,
                            label_visibility="collapsed"
                        )
                        if i < len(source_docs):
                            st.markdown("---")
        
        # ç”Ÿæˆå•æ¡è¯„è®ºçš„ Action Plan
        st.markdown("---")
        st.markdown("### ğŸ’¡ è¡ŒåŠ¨å»ºè®®")
        
        action_plan = generate_action_plan(
            topic_name="å•æ¡è¯„è®ºåˆ†æ",
            rag_conclusion=conclusion,
            user_complaints=[user_input],
            llm=llm
        )
        
        if action_plan:
            action_type = action_plan.get('action_type', 'Doc Update')
            title = action_plan.get('title', '')
            content = action_plan.get('content', '')
            priority = action_plan.get('priority', 'Medium')
            
            # ä¼˜å…ˆçº§é¢œè‰²
            priority_colors = {
                "High": "ğŸ”´",
                "Medium": "ğŸŸ¡",
                "Low": "ğŸŸ¢"
            }
            priority_icon = priority_colors.get(priority, "ğŸŸ¡")
            
            # è¡ŒåŠ¨ç±»å‹å›¾æ ‡
            type_icons = {
                "Jira Ticket": "ğŸ",
                "Doc Update": "ğŸ“",
                "Email Draft": "ğŸ“§",
                "Meeting": "ğŸ“…"
            }
            type_icon = type_icons.get(action_type, "ğŸ“‹")
            
            with st.expander(f"{type_icon} **{title}** Â· {priority_icon} {priority} Â· {action_type}", expanded=True):
                st.markdown(f"**ä¼˜å…ˆçº§ï¼š** {priority}")
                st.markdown(f"**ç±»å‹ï¼š** {action_type}")
                st.markdown(f"**å†…å®¹ï¼š**")
                if len(content) > 500:
                    st.text_area("", value=content, height=150, disabled=True, key="manual_action_content", label_visibility="collapsed")
                else:
                    st.markdown(content)
                
                # Mock æŒ‰é’®
                if action_type == "Jira Ticket":
                    if st.button("ğŸš€ æ¨é€è‡³ Jira", key="manual_jira", use_container_width=True):
                        ticket_id = f"DJI-2025-{random.randint(800, 999)}"
                        st.toast(f"âœ… å·¥å•å·²åˆ›å»ºï¼Ticket ID: {ticket_id}", icon="ğŸ‰")
                elif action_type == "Doc Update":
                    if st.button("ğŸ“ åˆ›å»º Notion Task", key="manual_notion", use_container_width=True):
                        st.toast("âœ… Notion ä»»åŠ¡å·²åˆ›å»ºï¼", icon="ğŸ‰")
                elif action_type == "Email Draft":
                    if st.button("ğŸ“§ å¤åˆ¶é‚®ä»¶", key="manual_email", use_container_width=True):
                        st.toast("âœ… é‚®ä»¶å†…å®¹å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼", icon="ğŸ‰")
                elif action_type == "Meeting":
                    if st.button("ğŸ“… åˆ›å»ºä¼šè®®", key="manual_meeting", use_container_width=True):
                        st.toast("âœ… ä¼šè®®å·²åˆ›å»ºï¼", icon="ğŸ‰")
    else:
        st.info("ğŸ‘† è¯·è¾“å…¥ç”¨æˆ·è¯„è®ºå¹¶ç‚¹å‡»ã€Œå¼€å§‹å½’å› åˆ†æã€æŒ‰é’®")

